{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc2df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from scipy import signal\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "# os.environ[\"MP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e3103",
   "metadata": {},
   "source": [
    "## Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e539c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_linear(nn.Module):\n",
    "    def __init__(self,chunk =10,sigmoid_state=True,len_input = 16,outputa = 50):\n",
    "        super().__init__()\n",
    "        if chunk == 10:\n",
    "            sep = 384//4 # due to 2 maxPool1d Kernel_size = 2\n",
    "        if chunk == 50:\n",
    "            sep = 1280\n",
    "        if chunk == 100:\n",
    "            sep = 3200//4\n",
    "        if chunk == 200:\n",
    "            sep = 6400//4\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(chunk,128)\n",
    "        \n",
    "        self.biLSTM = nn.LSTM(chunk,128,bidirectional=True)\n",
    "        self.linear1 = nn.Linear(7168,128)\n",
    "        self.Lazyl1 = nn.LazyLinear(128)\n",
    "        self.linear2 = nn.Linear(128,outputa)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "        self.sigmoid_state = sigmoid_state\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1,(hn,cn) = self.biLSTM(x)\n",
    "        out1 = out1.flatten()\n",
    "        output = self.Lazyl1(out1)\n",
    "        y_final = self.linear2(output)\n",
    "        \n",
    "        if self.sigmoid_state:\n",
    "            y_final = self.sigmoid(y_final)\n",
    "        else:\n",
    "            y_final = self.softmax(y_final)\n",
    "\n",
    "        return y_final\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path,\n",
    "                 batch=16,\n",
    "                 chunk = 100,\n",
    "                 vocab_path = \"../Sign_Language_Detection/label.json\",\n",
    "                table:bool = False,\n",
    "                dataframe=None):\n",
    "        \n",
    "        \n",
    "        with open(vocab_path,\"r\") as f:\n",
    "            compare = json.load(f)\n",
    "        self.vocab = len(compare)\n",
    "        \n",
    "        if not table:\n",
    "            self._data_csv = pd.read_csv(csv_path)\n",
    "        else:\n",
    "            self._data_csv = dataframe\n",
    "        \n",
    "        \n",
    "        self._data_csv = self._data_csv[~(self._data_csv.Label.isin([ \"cooldown\",\"error_redo\",\"break_time\",]))]\n",
    "        self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
    "        self.train_data = self.convert_data_csv_train(self._data_csv,compare,segment=chunk,range_data=25)\n",
    "        # print(len(self.train_data))\n",
    "        \n",
    "        print(self.train_data.size())\n",
    "        fity = []\n",
    "        normal =[]\n",
    "        for i in self.train_data:\n",
    "            # print(i[:,-1][0])\n",
    "            if int(i[:,-1][-1]) == 0:\n",
    "                fity.append(i)\n",
    "            else:\n",
    "                normal.append(i)\n",
    "        # print(len(fity))\n",
    "        # print(len(normal))\n",
    "        fity = random.sample(fity,int(len(fity) * 0.5))\n",
    "        normal.extend(fity)\n",
    "        self.train_data = normal\n",
    "        self.nums  = len(self.train_data)\n",
    "        self.answer_transform = []\n",
    "    \n",
    "        self.train_data = torch.tensor([i.tolist() for i in self.train_data])\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(self.train_data)):\n",
    "            # print(self.train_data)\n",
    "            \n",
    "            \n",
    "            dummy = torch.zeros(self.vocab)\n",
    "            ct = Counter(self.train_data[i][:,-1].tolist()).most_common()\n",
    "            if len(ct) == 2 and ct[0][0] ==0:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[1]\n",
    "            else:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[0]\n",
    "            \n",
    "            dummy[int(idx)] = 1\n",
    "            self.answer_transform.append(dummy)\n",
    "        \n",
    "        self.train_data = self.train_data[:,:,:-1]\n",
    "        self.nums,self.segment,self.input = self.train_data.size()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.train_data[index]\n",
    "        answer = self.answer_transform[index]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            return inputs.to(torch.float32).movedim(1,0).to(\"cuda\"),answer.to(\"cuda\")\n",
    "        else:\n",
    "            return inputs.to(torch.float32).movedim(1,0),answer\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def len_answer(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def data_info(self):\n",
    "        return self.nums,self.segment,self.input,self.train_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def convert_data_csv_train(self,data,compare,segment=50,range_data = 0):\n",
    "\n",
    "        datta = []\n",
    "        previous = None\n",
    "        samples = []\n",
    "        abc= []\n",
    "        \n",
    "        \n",
    "        data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n",
    "        grouped_dfs = [g.drop(columns='group_id').values for _, g in data.groupby('group_id')]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"len(data): \",len(grouped_dfs))\n",
    "        print(\"filter Value\")\n",
    "        all_data = []\n",
    "        for i in tqdm(grouped_dfs,total = len(grouped_dfs)):\n",
    "            if len(i) > range_data:\n",
    "                all_data.append(i)\n",
    "\n",
    "\n",
    "        print(\"pad&mean Value\")\n",
    "\n",
    "        real = []\n",
    "        for i in tqdm(all_data,total = len(all_data)):\n",
    "            segment = segment\n",
    "            if len(i) < segment:\n",
    "                tensor_df = (torch.tensor(i))\n",
    "                n,b = tensor_df.size()\n",
    "                padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, segment-n, 0), mode='constant', value=0)\n",
    "                # print(padded_tensor.size())\n",
    "                real.append(padded_tensor.tolist())\n",
    "            else:\n",
    "                step = int(np.ceil(len(i)//segment))\n",
    "                temp = []\n",
    "                for k in range(segment):\n",
    "                    temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "                real.append(temp)\n",
    "\n",
    "        train_data = torch.tensor(real)\n",
    "        return train_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49c8ab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7565c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481770\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "for i in glob.glob(r\"./collect_data/new_data/*\"):\n",
    "    df = pd.read_csv(rf\"{i}\")\n",
    "    base_df = pd.concat([base_df,df])\n",
    "print(len(base_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d137af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=50,table=True,dataframe=base_df)\n",
    "# data_answer = []\n",
    "# for inputs,answer in tqdm(train_dataset):\n",
    "      \n",
    "      # try:\n",
    "          # print(torch.tensor(inputs[i:i+chunk]).size())\n",
    "    #   data_answer.append(answer)\n",
    "\n",
    "\n",
    "# train.size()\n",
    "\n",
    "# with open(\"rollback.json\",'r') as f:\n",
    "#     ct = json.load(f)\n",
    "    \n",
    "    \n",
    "# print(len(data_answer))\n",
    "# label_list = [int(torch.argmax(i)) for i in data_answer] \n",
    "# nv = Counter(label_list)\n",
    "# print(nv.most_common())\n",
    "\n",
    "\n",
    "\n",
    "# not_eng = []\n",
    "# for i,v in nv.most_common():\n",
    "#     print(f\"{ct[str(i)]} : {v} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f223ea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\887024777.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\887024777.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extrac Value\n",
      "len(data):  6811\n",
      "filter Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c702527d9b3b48619953de186c9c2b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a0609de2fb45c3a1344f4876726106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3579, 50, 30])\n",
      " data train = 3490 with 29 feature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116195b3233045c39f976de6542917cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1 loss = 0.01996440440416336 with lr = [2e-05]\n",
      "best loss at epoch = 1 with 0.01996440440416336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch = 1\n",
    "lr = 2e-5\n",
    "chunk = 50\n",
    "e = 0\n",
    "best_loss = 0\n",
    "path_save = \"../Sign_Language_Detection/model/Version1\"\n",
    "num_still = 0\n",
    "sigoid_state = True\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=50,table=True,dataframe=base_df)\n",
    "\n",
    "\n",
    "len_output = train_dataset.len_answer()\n",
    "len_input = train_dataset.data_info()[-2]\n",
    "train_dataset = DataLoader(train_dataset,batch_size=batch_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  lstm = lstm_linear(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output).to(\"cuda\")\n",
    "else:\n",
    "  lstm = lstm_linear(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(),lr=lr,weight_decay=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',patience =3  ,min_lr = 5e-6,factor=0.5)\n",
    "print(f\" data train = {int(len(train_dataset)*batch_size)} with {len_input} feature\")\n",
    "\n",
    "\n",
    "n = 0\n",
    "for param in lstm.parameters():\n",
    "  param.requires_grad=True\n",
    "lstm.train()\n",
    "\n",
    "for k in range(1,epoch+1):\n",
    "    loss_total = 0\n",
    "    data_answer = []\n",
    "    for inputs,answer in tqdm(train_dataset):\n",
    "      answer = answer[0]\n",
    "      data_answer.append(answer)\n",
    "      output = lstm(inputs)\n",
    "      optimizer.zero_grad()\n",
    "      if torch.argmax(answer).item() == 0:\n",
    "        loss = criterion(output,answer)\n",
    "      else:\n",
    "        loss = criterion(output,answer)\n",
    "      \n",
    "      \n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_total += loss\n",
    "      n+=1\n",
    "        \n",
    "    if best_loss == 0 or best_loss > loss_total/len(train_dataset):\n",
    "      best_loss = loss_total/len(train_dataset)\n",
    "      state_dict = lstm.state_dict()\n",
    "      e = k\n",
    "      num_still = 0\n",
    "    else:\n",
    "      num_still +=1\n",
    "      \n",
    "    scheduler.step(loss_total/len(train_dataset))\n",
    "    num_still = 0\n",
    "    if num_still >= 3:\n",
    "      print(\"step up to learning = \",scheduler.get_last_lr())\n",
    "      break\n",
    "      \n",
    "    \n",
    "    print(f\"epoch number {k} loss = {loss_total/len(train_dataset)} with lr = {scheduler.get_last_lr()}\")\n",
    "print(f\"best loss at epoch = {e} with {best_loss}\")\n",
    "torch.save(state_dict,f\"{path_save}/model_epoch_{e}\")\n",
    "torch.save(lstm, r\"./model/Version1/finalmodel.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9559fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extrac Value\n",
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\887024777.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\887024777.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b205290a384403daa7825c49e483346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90938c47ceea45c8a7ace8f7814ad5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15108d7d833a471eac5ff5a7093c2889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "# test_df  = test_df[test_df.columns[1:]]\n",
    "test_dataset = CustomDataset(\"collect_data/20250624_131408_พชชาภา24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=test_df)\n",
    "test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,answer in tqdm(test_dataset):\n",
    "        output = lstm(inputs)\n",
    "        y_pred += [(torch.argmax(output,dim=0)).tolist()]\n",
    "        y_true += (torch.argmax(answer,dim=1)).tolist()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9202f260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.10091743119266056\n",
      "recal score  0.10091743119266056\n",
      "acc score    0.10091743119266056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,accuracy_score\n",
    "f1_scores = f1_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"f1 score    \",f1_scores)\n",
    "recall_scores = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"recal score \",recall_scores)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"acc score   \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6ef8d",
   "metadata": {},
   "source": [
    "# How to use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b5a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_csv_train(data,segment=50):\n",
    "\n",
    "    real = []\n",
    "    for i in tqdm(data,total = len(data)):\n",
    "        segment = segment\n",
    "        if len(i) < segment:\n",
    "            # tensor_df = (torch.tensor(i.clone()))\n",
    "            tensor_df = i.clone()\n",
    "            n,b = tensor_df.size()\n",
    "            padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, segment-n, 0), mode='constant', value=0)\n",
    "            # print(padded_tensor.size())\n",
    "            real.append(padded_tensor.tolist())\n",
    "        else:\n",
    "            step = int(np.ceil(len(i)//segment))\n",
    "            temp = []\n",
    "            for k in range(segment):\n",
    "                temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "            real.append(temp)\n",
    "    return torch.tensor(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c441d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r\"./model/Version1/finalmodel.pt\",weights_only=False)\n",
    "with open(r\"rollback.json\",'r') as f:\n",
    "    vocap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e397707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32e28e9b0314169942bf6e2c61b1669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29, 50])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(1,29)\n",
    "datas = torch.rand(1,29)\n",
    "i=0\n",
    "while i<20:\n",
    "    \n",
    "    ### you need to put a streaming inout here\n",
    "    \n",
    "    \n",
    "    datas = torch.concat([datas,data])\n",
    "    i+=1\n",
    "    \n",
    "tas = convert_data_csv_train(datas.unsqueeze(0))\n",
    "tas = tas.movedim(1,2)\n",
    "answer = torch.argmax(model(tas))\n",
    "finalans = vocap[str(answer.item())]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
