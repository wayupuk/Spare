{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc2df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from scipy import signal\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# os.environ[\"MP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e3103",
   "metadata": {},
   "source": [
    "## Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e539c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_linear(nn.Module):\n",
    "    def __init__(self,chunk =10,sigmoid_state=True,len_input = 16,outputa = 50):\n",
    "        super().__init__()\n",
    "        \n",
    "        h_ = 128\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.biLSTM = nn.LSTM(chunk,h_,bidirectional=True)\n",
    "        self.linear1 = nn.Linear((h_ * 2 * len_input),128)\n",
    "        # self.linear2 = nn.Linear(128,128)\n",
    "        self.Lazyl1 = nn.LazyLinear(128)\n",
    "        self.linear2 = nn.Linear(128,outputa)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid_state = sigmoid_state\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1,(hn,cn) = self.biLSTM(x)\n",
    "        \n",
    "        # print(out1.size())\n",
    "        b,f,o = out1.size()\n",
    "        # out1 = out1.flatten()\n",
    "        \n",
    "        out1 = out1.reshape(b,-1)\n",
    "        \n",
    "        output = self.linear1(self.relu(out1))\n",
    "        # output = self.linear2(self.relu(output))\n",
    "        y_final = self.linear2(self.relu(output))\n",
    "        \n",
    "        # if self.sigmoid_state:\n",
    "        #     y_final = self.sigmoid(y_final)\n",
    "        # else:\n",
    "        #     y_final = self.softmax(y_final)\n",
    "\n",
    "        return y_final\n",
    "\n",
    "class cnn_lstm(nn.Module):\n",
    "    def __init__(self,chunk =10,sigmoid_state=True,len_input = 16,outputa = 50):\n",
    "        super().__init__()\n",
    "        \n",
    "        h_ = 128\n",
    "        \n",
    "        # self.conv2d1 = nn.Conv2d(1,32,kernel_size=(3,3))\n",
    "        # self.conv2d2 = nn.Conv2d(32,64,kernel_size=(3,3))\n",
    "        # self.conv2d3 = nn.Conv2d(64,64,kernel_size=(3,3))\n",
    "        h1, w1 = chunk // 2, len_input // 2\n",
    "        h2, w2 = h1 // 2, w1 // 2\n",
    "        h3, w3 = h2, w2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.normalization = nn.BatchNorm1d(len_input)\n",
    "        self.conv2d1 = nn.Conv2d(1,32,kernel_size=(3,3),padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2d2 = nn.Conv2d(32,64,kernel_size=(3,3),padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2d3 = nn.Conv2d(64,128,kernel_size=(3,3),padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.lstm = nn.LSTM(12*7,256)\n",
    "        \n",
    "        self.linear1 = nn.Linear(128*h3*w3,64)\n",
    "        self.linear2 = nn.Linear(64,outputa)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Normalize along feature dimension\n",
    "        # Reshape for BatchNorm1d: (batch_size * seq_len, n_features)\n",
    "        x_norm = x.view(-1, x.size(2))\n",
    "        x_norm = self.normalization(x_norm)\n",
    "        x = x_norm.view(batch_size, x.size(1), x.size(2))\n",
    "        \n",
    "        # out1 = self.batch_norm(x)\n",
    "        \n",
    "        out1 = x.unsqueeze(1)\n",
    "        # print(out1)\n",
    "        out1 = self.conv2d1(out1)\n",
    "        out1 = self.maxpool1(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        \n",
    "        out1 = self.conv2d2(out1)\n",
    "        out1 = self.maxpool2(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        \n",
    "        out1 = self.conv2d3(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        \n",
    "        out1 = out1.view(batch_size, -1)\n",
    "         \n",
    "        out = self.linear1(out1)                        \n",
    "        out = self.linear2(out)                             \n",
    "        # if self.sigmoid_state:\n",
    "        #     y_final = self.sigmoid(y_final)\n",
    "        # else:\n",
    "        #     y_final = self.softmax(y_final)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNNTimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, input_shape, n_classes, dropout=0.3):\n",
    "        \"\"\"\n",
    "        CNN-based Time Series Classifier following your architecture diagram\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Tuple (sequence_length, n_features) - e.g., (121, 21)\n",
    "            n_classes: Number of output classes\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(CNNTimeSeriesClassifier, self).__init__()\n",
    "        \n",
    "        seq_len, n_features = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_rate = dropout\n",
    "        \n",
    "        # Input normalization layer\n",
    "        self.normalization = nn.BatchNorm1d(n_features)\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch, channels, height, width)\n",
    "        # We'll treat sequence as height and features as width, with 1 channel\n",
    "        # Input shape: (None, 1, seq_len, n_features) - e.g., (None, 1, 121, 21)\n",
    "        # First Conv2D block\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, \n",
    "            out_channels=32, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after first conv+pool\n",
    "        # After conv1: (None, 32, 121, 21) -> (None, 32, 119, 19) with padding=1\n",
    "        # After pool1: (None, 32, 119, 19) -> (None, 32, 59, 9)\n",
    "        h1, w1 = seq_len // 2, n_features // 2\n",
    "        \n",
    "        # Second Conv2D block\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after second conv+pool\n",
    "        # After conv2: (None, 64, 59, 9) -> (None, 64, 57, 7) with padding=1\n",
    "        # After pool2: (None, 64, 57, 7) -> (None, 64, 28, 3)\n",
    "        h2, w2 = h1 // 2, w1 // 2\n",
    "        \n",
    "        # Third Conv2D block\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        # Calculate final conv output shape\n",
    "        # After conv3: (None, 64, 28, 3) -> (None, 64, 26, 1) with padding=1\n",
    "        h3, w3 = h2, w2\n",
    "        \n",
    "        # Calculate flattened size dynamically\n",
    "        self.flatten_size = 64 * h3 * w3\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 64)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "        # Activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights properly\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, n_features)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Normalize along feature dimension\n",
    "        # Reshape for BatchNorm1d: (batch_size * seq_len, n_features)\n",
    "        x_norm = x.view(-1, x.size(2))\n",
    "        x_norm = self.normalization(x_norm)\n",
    "        x = x_norm.view(batch_size, x.size(1), x.size(2))\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch_size, 1, seq_len, n_features)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # First Conv2D + MaxPool2D\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second Conv2D + MaxPool2D\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Third Conv2D\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # First Dense layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Dense layer (output)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return model configuration for saving\"\"\"\n",
    "        return {\n",
    "            'input_shape': self.input_shape,\n",
    "            'n_classes': self.n_classes,\n",
    "            'dropout': self.dropout_rate,\n",
    "            'flatten_size': self.flatten_size\n",
    "        }\n",
    "\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path,\n",
    "                 batch=16,\n",
    "                 chunk = 100,\n",
    "                 vocab_path = \"../Sign_Language_Detection/label.json\",\n",
    "                table:bool = False,\n",
    "                dataframe=None):\n",
    "        \n",
    "        \n",
    "        with open(vocab_path,\"r\") as f:\n",
    "            compare = json.load(f)\n",
    "        self.vocab = len(compare)\n",
    "        \n",
    "        if not table:\n",
    "            self._data_csv = pd.read_csv(csv_path)\n",
    "        else:\n",
    "            self._data_csv = dataframe\n",
    "        \n",
    "        \n",
    "        self._data_csv = self._data_csv[~(self._data_csv.Label.isin([ \"cooldown\",\"error_redo\",\"break_time\",]))]\n",
    "        self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
    "        self._data_csv = self._data_csv.drop(columns=[\"timestamp_ms\"])\n",
    "        self.train_data = self.convert_data_csv_train(self._data_csv,compare,segment=chunk,range_data=25)\n",
    "        # print(len(self.train_data))\n",
    "        \n",
    "        print(self.train_data.size())\n",
    "        fity = []\n",
    "        normal =[]\n",
    "        for i in self.train_data:\n",
    "            # print(i[:,-1][0])\n",
    "            if int(i[:,-1][-1]) == 0:\n",
    "                fity.append(i)\n",
    "            else:\n",
    "                normal.append(i)\n",
    "        # print(len(fity))\n",
    "        # print(len(normal))\n",
    "        fity = random.sample(fity,int(len(fity) * 0.5))\n",
    "        normal.extend(fity)\n",
    "        self.train_data = normal\n",
    "        self.nums  = len(self.train_data)\n",
    "        self.answer_transform = []\n",
    "    \n",
    "        self.train_data = torch.tensor([i.tolist() for i in self.train_data])\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(self.train_data)):\n",
    "            # print(self.train_data)\n",
    "            \n",
    "            \n",
    "            dummy = torch.zeros(self.vocab)\n",
    "            ct = Counter(self.train_data[i][:,-1].tolist()).most_common()\n",
    "            if len(ct) == 2 and ct[0][0] ==0:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[1]\n",
    "            else:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[0]\n",
    "            # print(Counter(self.train_data[i][:,-1].tolist()).most_common())\n",
    "\n",
    "            dummy[int(idx)] = 1\n",
    "            self.answer_transform.append(dummy)\n",
    "        \n",
    "        self.train_data = self.train_data[:,:,:-1]\n",
    "        self.nums,self.segment,self.input = self.train_data.size()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.train_data[index]\n",
    "        answer = self.answer_transform[index]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            return inputs.to(torch.float32).to(\"cuda\"),answer.to(\"cuda\")\n",
    "        else:\n",
    "            return inputs.to(torch.float32),answer\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def len_answer(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def data_info(self):\n",
    "        return self.nums,self.segment,self.input,self.train_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def convert_data_csv_train(self,data,compare,segment=50,range_data = 0):\n",
    "\n",
    "        datta = []\n",
    "        previous = None\n",
    "        samples = []\n",
    "        abc= []\n",
    "        \n",
    "        \n",
    "        data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n",
    "        grouped_dfs = [g.drop(columns='group_id').values for _, g in data.groupby('group_id')]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"len(data): \",len(grouped_dfs))\n",
    "        print(\"filter Value\")\n",
    "        all_data = []\n",
    "        for i in tqdm(grouped_dfs,total = len(grouped_dfs)):\n",
    "            if len(i) > range_data:\n",
    "                all_data.append(i)\n",
    "\n",
    "\n",
    "        print(\"pad&mean Value\")\n",
    "\n",
    "        real = []\n",
    "        for i in tqdm(all_data,total = len(all_data)):\n",
    "            segment = segment\n",
    "            if len(i) < segment:\n",
    "                tensor_df = (torch.tensor(i))\n",
    "                n,b = tensor_df.size()\n",
    "                padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, 0,segment-n), mode='constant', value=0)\n",
    "                # print(padded_tensor.size())\n",
    "                real.append(padded_tensor.tolist())\n",
    "            else:\n",
    "                step = int(np.ceil(len(i)//segment))\n",
    "                temp = []\n",
    "                for k in range(segment):\n",
    "                    temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "                real.append(temp)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        train_data = torch.tensor(real)\n",
    "        return train_data\n",
    "    \n",
    "class ImprovedCustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, chunk_size=121, label_encoder=None, is_test=False, \n",
    "                 balance_classes=False, min_sequence_length=50,zero_ratio=1,down_zero=True):\n",
    "        \"\"\"\n",
    "        Improved dataset class for CNN time series classification\n",
    "        \n",
    "        Args:\n",
    "            dataframe: Input dataframe\n",
    "            chunk_size: Sequence length for time series (121 to match your diagram)\n",
    "            label_encoder: Pre-fitted label encoder (for test data)\n",
    "            is_test: Whether this is test data\n",
    "            balance_classes: Whether to balance classes\n",
    "            min_sequence_length: Minimum sequence length to keep\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.min_sequence_length = min_sequence_length\n",
    "        \n",
    "        # Clean data\n",
    "        self.data = dataframe.copy()\n",
    "        self.data = self.data[~self.data.Label.isin([\"cooldown\", \"error_redo\", \"break_time\"])]\n",
    "        \n",
    "        # Handle label encoding\n",
    "        if label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.data[\"Label\"] = self.label_encoder.fit_transform(self.data[\"Label\"])\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            # Handle unseen labels in test data\n",
    "            known_labels = set(label_encoder.classes_)\n",
    "            mask = self.data[\"Label\"].isin(known_labels)\n",
    "            if not mask.all():\n",
    "                print(f\"Warning: Removing {(~mask).sum()} samples with unknown labels\")\n",
    "                self.data = self.data[mask]\n",
    "            self.data[\"Label\"] = label_encoder.transform(self.data[\"Label\"])\n",
    "        \n",
    "        self.n_classes = len(self.label_encoder.classes_)\n",
    "        \n",
    "        # Remove timestamp if present\n",
    "        if \"timestamp_ms\" in self.data.columns:\n",
    "            self.data = self.data.drop(columns=[\"timestamp_ms\"])\n",
    "        \n",
    "        # Convert to sequences\n",
    "        self.sequences, self.labels = self._create_sequences()\n",
    "        \n",
    "        # Balance classes if requested and not test data\n",
    "        if balance_classes and not is_test:\n",
    "            self.sequences, self.labels = self._balance_classes()\n",
    "        \n",
    "        if down_zero and not is_test:\n",
    "            self.sequences, self.labels = self._down_zero(zero_ratio = zero_ratio)\n",
    "            \n",
    "        \n",
    "        print(f\"Dataset created: {len(self.sequences)} sequences of shape {self.sequences.shape}\")\n",
    "        print(f\"Classes: {self.n_classes}, Distribution: {Counter(self.labels.numpy())}\")\n",
    "    \n",
    "    def _create_sequences(self):\n",
    "        \"\"\"Create sequences from grouped data\"\"\"\n",
    "        # Group by consecutive labels\n",
    "        self.data['group_id'] = (self.data['Label'] != self.data['Label'].shift()).cumsum()\n",
    "        grouped_data = [group.drop('group_id', axis=1) for _, group in self.data.groupby('group_id')]\n",
    "        \n",
    "        print(f\"Found {len(grouped_data)} label groups\")\n",
    "        \n",
    "        # Filter by minimum length\n",
    "        valid_groups = [group for group in grouped_data if len(group) >= self.min_sequence_length]\n",
    "        print(f\"Kept {len(valid_groups)} groups after length filtering\")\n",
    "        \n",
    "        sequences = []\n",
    "        labels = []\n",
    "        \n",
    "        for group in tqdm(valid_groups, desc=\"Processing sequences\"):\n",
    "            # Separate features and labels\n",
    "            features = group.drop('Label', axis=1).values\n",
    "            group_labels = group['Label'].values\n",
    "            \n",
    "            # Get the most common label in the sequence\n",
    "            most_common_label = Counter(group_labels).most_common(1)[0][0]\n",
    "            \n",
    "            # Create fixed-length sequence\n",
    "            if len(features) >= self.chunk_size:\n",
    "                # If longer than chunk_size, use uniform sampling\n",
    "                indices = np.linspace(0, len(features)-1, self.chunk_size, dtype=int)\n",
    "                sequence = features[indices]\n",
    "            else:\n",
    "                # If shorter, pad with zeros at the end\n",
    "                sequence = np.zeros((self.chunk_size, features.shape[1]))\n",
    "                sequence[:len(features)] = features\n",
    "            \n",
    "            sequences.append(sequence)\n",
    "            labels.append(most_common_label)\n",
    "        \n",
    "        return torch.FloatTensor(sequences), torch.LongTensor(labels)\n",
    "    \n",
    "    def _balance_classes(self):\n",
    "        \"\"\"Balance classes by undersampling majority classes\"\"\"\n",
    "        # Get class counts\n",
    "        unique_labels, counts = torch.unique(self.labels, return_counts=True)\n",
    "\n",
    "        min_count = counts.min().item()\n",
    "        \n",
    "        print(f\"Balancing classes to {min_count} samples each\")\n",
    "        \n",
    "        balanced_sequences = []\n",
    "        balanced_labels = []\n",
    "        \n",
    "        for label,counts in zip(unique_labels,counts):\n",
    "            # Get indices for this class\n",
    "            class_indices = (self.labels == label).nonzero(as_tuple=True)[0]\n",
    "            # Sample min_count indices\n",
    "            # if len(class_indices) > min_count and label.item() == 0:\n",
    "            #     sampled_indices = class_indices[torch.randperm(len(class_indices))[:int(counts.item() * zero_ratio )]]\n",
    "            if len(class_indices) > min_count:\n",
    "                sampled_indices = class_indices[torch.randperm(len(class_indices))[:min_count]]\n",
    "            else:\n",
    "                sampled_indices = class_indices\n",
    "            \n",
    "            balanced_sequences.append(self.sequences[sampled_indices])\n",
    "            balanced_labels.append(self.labels[sampled_indices])\n",
    "        \n",
    "        return torch.cat(balanced_sequences), torch.cat(balanced_labels)\n",
    "    \n",
    "    def _down_zero(self,zero_ratio = 1):\n",
    "        \"\"\"Balance classes by undersampling majority classes\"\"\"\n",
    "        # Get class counts\n",
    "        unique_labels, counts = torch.unique(self.labels, return_counts=True)\n",
    "\n",
    "        \n",
    "        print(f\"down zero with {zero_ratio} ratio\")\n",
    "        \n",
    "        balanced_sequences = []\n",
    "        balanced_labels = []\n",
    "        \n",
    "        for label,counts in zip(unique_labels,counts):\n",
    "            # Get indices for this class\n",
    "            class_indices = (self.labels == label).nonzero(as_tuple=True)[0]\n",
    "            # Sample min_count indices\n",
    "            if label.item() == 0:\n",
    "                sampled_indices = class_indices[torch.randperm(len(class_indices))[:int(counts.item() * zero_ratio )]]\n",
    "            else:\n",
    "                sampled_indices = class_indices\n",
    "            \n",
    "            balanced_sequences.append(self.sequences[sampled_indices])\n",
    "            balanced_labels.append(self.labels[sampled_indices])\n",
    "        \n",
    "        return torch.cat(balanced_sequences), torch.cat(balanced_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "    \n",
    "    def get_info(self):\n",
    "        \"\"\"Return dataset information\"\"\"\n",
    "        return {\n",
    "            'n_samples': len(self.sequences),\n",
    "            'sequence_length': self.chunk_size,\n",
    "            'n_features': self.sequences.shape[2],\n",
    "            'n_classes': self.n_classes,\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'class_names': self.label_encoder.classes_,\n",
    "            'input_shape': (self.chunk_size, self.sequences.shape[2])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49c8ab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe8bd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35e7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = r\"\"\"data\\2025-06-24\\data\\20250624_081243_test01_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_084604_session_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_091423_session_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_091650_กองภพ24062025_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_101902_ชาตชาย24062025_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_131408_พชชาภา24062025_sensor.csv\n",
    "data\\2025-06-24\\data\\20250624_152920_ภรณภทร24062_sensor.csv\n",
    "data\\8-7-2025\\data\\20250708_130659_Fahsai_ทหลง2_sensor.csv\n",
    "data\\8-7-2025\\data\\20250708_131357_Fahsai_ทน2_sensor.csv\n",
    "data\\8-7-2025\\data\\20250708_131831_Fahsai_ทนน2_sensor.csv\n",
    "data\\8-7-2025\\data\\20250708_132327_Fahsai_คำถาม2_sensor.csv \n",
    "data\\8-7-2025\\data\\20250708_133838_Fahsai_รอ_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_131551_Fahsai_ใหญ_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_132015_Fahsai_เลก_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_132533_Fahsai_รอน_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_133524_Fahsai_วนน_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_134251_Fahsai_พรงน_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_134758_Fahsai_เมอวาน_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_144852_Fahsai_บาน2_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_145353_Fahsai_โรงเรยน_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_154934_Fahsai_หนงสอ_sensor.csv\n",
    "data\\Data 7-7-2025\\data\\20250707_155036_Fahsai_หนงสอ2_sensor.csv\n",
    " data\\Data 7-7-2025\\data\\20250707_163136_Fahsai_ทหลง_sensor.csv\"\"\"\n",
    "dat = dat.split(\"\\n\")\n",
    "not_include = [i.split(\"\\\\\")[-1]  for i in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7565c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596008\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "# for i in glob.glob(r\"./collect_data/new_data/*\"):\n",
    "    # if i.split(\"\\\\\")[-1] not in not_include:\n",
    "df = pd.read_csv(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\normal_train_data.csv\")\n",
    "base_df = pd.concat([base_df,df])   \n",
    "print(len(base_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86d137af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=50,table=True,dataframe=base_df)\n",
    "# data_answer = []\n",
    "# for inputs,answer in tqdm(train_dataset):\n",
    "      \n",
    "      # try:\n",
    "          # print(torch.tensor(inputs[i:i+chunk]).size())\n",
    "    #   data_answer.append(answer)\n",
    "\n",
    "\n",
    "# train.size()\n",
    "\n",
    "# with open(\"rollback.json\",'r') as f:\n",
    "#     ct = json.load(f)\n",
    "    \n",
    "    \n",
    "# print(len(data_answer))\n",
    "# label_list = [int(torch.argmax(i)) for i in data_answer] \n",
    "# nv = Counter(label_list)\n",
    "# print(nv.most_common())\n",
    "\n",
    "\n",
    "\n",
    "# not_eng = []\n",
    "# for i,v in nv.most_common():\n",
    "#     print(f\"{ct[str(i)]} : {v} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f223ea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  9669\n",
      "filter Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc9203dd8804888895a2ba17313002b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c271b89d957a4eb2aa04cc6764c77888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4986, 50, 29])\n",
      " data train = 4992 with 28 feature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1aa9de5b6243f792be93caeaa7c254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1 loss = 3.966810941696167 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1721b7b710c43c0addc0705f4c7c2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2 loss = 3.5274884700775146 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861a4735fe094ef9a3e4e2acdf2ff643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 3 loss = 3.040966272354126 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e30c05392414356b3fd5eac8c8a00e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 4 loss = 2.638681173324585 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cb6569ca3b4c909dde2bd01f745ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5 loss = 2.269826650619507 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e76da3235a54c17ad249675a7a8c398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 6 loss = 1.944569706916809 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420d989c9608463b9993fc5345dfc196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 7 loss = 1.6930173635482788 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb8cae7f9b24964be554354f9d4a599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8 loss = 1.5073882341384888 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa2ddcb65e44162839bb13cfe20e881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 9 loss = 1.3252522945404053 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5a6e1b97804ae2a8b508370902b4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560b43a95cf54bedb057fbbb96c4e601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f66d0809c453f867e5f9773aae64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96efcb9632584822a366c01d3430a549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.08256880733944955\n",
      "recal score  0.08256880733944955\n",
      "acc score    0.08256880733944955\n",
      "epoch number 10 loss = 1.190516710281372 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985aef27669040c092f7cfcfe504e113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 11 loss = 1.0761864185333252 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f6a01d17e14a899f23ffc5fcad72fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 12 loss = 1.0038971900939941 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9f36eeadf40b3813421fa8763c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 13 loss = 0.8945263624191284 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f2dda05af34ff5b7c5971b744caa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 14 loss = 0.8171292543411255 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a01a48e49ae4fad97e46403a00058e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 15 loss = 0.7471691370010376 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bb769a76984f4c90e86b23e3b6cfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 16 loss = 0.7157631516456604 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16cbed410384050b2298c08efe30cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 17 loss = 0.6234520673751831 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db6cddd441540b8a13ac815aeb57d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 18 loss = 0.564498782157898 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083c9e7c57624affa445f8995f4b5cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 19 loss = 0.5578475594520569 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac531a6f131f40f98e673c1950e366c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f4df3e47dc48c6b1557c4d07da11ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8142711ed8374d2f901722d9698e7c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7357d8a761a42378abadb911b886155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.22935779816513763\n",
      "recal score  0.22935779816513763\n",
      "acc score    0.22935779816513763\n",
      "epoch number 20 loss = 0.5265121459960938 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe2b521050444c6a5cae478c7a0a4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 21 loss = 0.5198546648025513 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db574fb6931446597141ee42c228702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 22 loss = 0.46611467003822327 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c49231cabcf479fb3283ba931cd6923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 23 loss = 0.4517858326435089 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f22301871e4faf8acc8061b4f9a6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 24 loss = 0.43720901012420654 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e027ac3498414eb4b54638bbcc0ce482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 25 loss = 0.43327298760414124 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cd18b66c734934b8252671b261a759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 26 loss = 0.41580185294151306 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992e69c1dfce410292051d8e1ef7cf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 27 loss = 0.37701570987701416 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877ed52c7aca4eb19dc501ad0285d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 28 loss = 0.3548657298088074 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d6309bd8be4cdaa95765900280d040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 29 loss = 0.35193535685539246 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326c9d84c6964ce18c2b1fe3e233c6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7118cd979b48419e64c5a69bceba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95e602827fb41f0811ba7a1e165aee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d33f7ae9fc4b67a5a159537c08006a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.22018348623853212\n",
      "recal score  0.22018348623853212\n",
      "acc score    0.22018348623853212\n",
      "epoch number 30 loss = 0.32058191299438477 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab0805440b14c82835c5bca8a439253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 31 loss = 0.3302856385707855 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70f7bf7baad4856a46e968d3c76e736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 32 loss = 0.3028872311115265 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3e43d5e708401db1c040c8b58488e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 33 loss = 0.2959426939487457 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335176a5ca9045969e093f4c5a0fbd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 34 loss = 0.3030009865760803 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060e53845e0459caa093c78c9aa064d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 35 loss = 0.31001606583595276 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aef0607d76483b9dd43a88eb1f25cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 36 loss = 0.2902292013168335 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33315eba96fd4e80a14f1fa761ab69dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 37 loss = 0.25565260648727417 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8294029dba4a54b5d55736827226a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 38 loss = 0.23614491522312164 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721bd59e798f4968af8635ae7493dfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 39 loss = 0.23578020930290222 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd58be7227e4603abc5f9ff2e2b1864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f57f787fd646dfa3ed25debe771aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30050c4659ff403da18e087b4b3965f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5c3eae3cc44daf80eeafb36550add3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.24770642201834864\n",
      "recal score  0.24770642201834864\n",
      "acc score    0.24770642201834864\n",
      "epoch number 40 loss = 0.21965213119983673 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0ed0e5368340cbad4c574ddf44c346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 41 loss = 0.23156891763210297 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c464052204849b09502027d7d8d83de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 42 loss = 0.20375221967697144 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77278f7dedb4a25bed0dfabaab28f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 43 loss = 0.2219984084367752 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc4aac1351e4df19b43df38d5f9a889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 44 loss = 0.23129262030124664 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043a2124f76446e79e9c65771e8e1f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 45 loss = 0.22519667446613312 with lr = [0.002]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9391188f6994c20bd8212d2f34780cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 46 loss = 0.2086806446313858 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27ba12187a440998abc47905ce57dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 47 loss = 0.18307188153266907 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2cb968b1a54743a1b0365dd761b2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 48 loss = 0.15982691943645477 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f74ce74c7e9479ba4221de3cba35324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 49 loss = 0.14121070504188538 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1b4d7e1135498a91cbe9c63b242aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7b5a49a01f4b3d8b2724913c11e0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde50cf5b801436f9fcf5c5f729c8b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ddd5bf934548abacf3385faed913f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.26605504587155965\n",
      "recal score  0.26605504587155965\n",
      "acc score    0.26605504587155965\n",
      "epoch number 50 loss = 0.14375536143779755 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b16b1d749449b1938437bc6d0817a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 51 loss = 0.1402113437652588 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191a0f0eff7b4ae087a0a892420dad82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 52 loss = 0.1456553190946579 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a08d25208e44b681a803672c462753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 53 loss = 0.13138258457183838 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55afbdd37294c86b37ec694aa73f7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 54 loss = 0.11326856911182404 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaff9bd3bee4da4b9d0fe166c5789ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 55 loss = 0.12183330208063126 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6949476880a54abd81cc26e57dfce3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 56 loss = 0.1335737109184265 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db52dc80f134e14b68f614d83eadff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 57 loss = 0.1300954818725586 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996b8924fea24460915ace2bcf5f54a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 58 loss = 0.1086534932255745 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9622c2dddaf04f749a18955ef91be991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 59 loss = 0.11448818445205688 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639bdb98670e4ad5ae5a03e1a06d4a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e63d471d984950aeefe877cf823706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ead1f29d9d24ce88991322041e26cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37306a35914190a998108a9d840f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.25688073394495414\n",
      "recal score  0.25688073394495414\n",
      "acc score    0.25688073394495414\n",
      "epoch number 60 loss = 0.10957182198762894 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9caba167a342f6985167610b16b713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 61 loss = 0.10585418343544006 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e69cc73152e4eb89fd750895d9f8c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 62 loss = 0.1089182123541832 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af525661651944d7a9c37191cdc7709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 63 loss = 0.10655288398265839 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6e540e534043f3826e9dcb9add56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 64 loss = 0.11251441389322281 with lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c248c09ecdb4944b8f54b2d8a393a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 65 loss = 0.11182815581560135 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2714fdad3e4954bd00094e55bc8ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 66 loss = 0.11771373450756073 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73583e58ac5a437aa4c2914438378bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 67 loss = 0.09148993343114853 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27fe95280fb436fa4fef8c4c2b03e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 68 loss = 0.09652650356292725 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5deebabb4a44ea699cee7bc87fab4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 69 loss = 0.0856914222240448 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d403eca803430f851e7f289cd620ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d237463e65c144ec83afe651cb21485c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441bac9ca878463492f39afbba0e730a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f8f65068f04f9aa61f1a1346e4f6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.27522935779816515\n",
      "recal score  0.27522935779816515\n",
      "acc score    0.27522935779816515\n",
      "epoch number 70 loss = 0.08333349227905273 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d1516706204a5488b8df4eac842aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 71 loss = 0.08332719653844833 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b655243eb0ba49b89abd77b37c7e7f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 72 loss = 0.07963559776544571 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3463eadc6c44c77b662d191f7a818ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 73 loss = 0.08330689370632172 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e888e354bb5f4aaab2857c7944d6cad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 74 loss = 0.08413112908601761 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c721c10fcda44debfb62908be0dcf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 75 loss = 0.0899544432759285 with lr = [0.0005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1557177ccb43698a53c832ca40d768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 76 loss = 0.08713801950216293 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbfd3dd6b4243bda8a313ed3c5f465e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 77 loss = 0.07257017493247986 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c56ea8d09f42c89eb9e6ab95cb26ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 78 loss = 0.07958416640758514 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86643f6f88844a91bb1fddeac4a9d778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 79 loss = 0.07901555299758911 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d65dbd9d9ed4c61a98c00c9c85c985b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737864ae821b499f8c7639591913552f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645fe8d740ab47b1ab59775a6e261d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ad4f644ea34bd3b74b0f428e9af9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.21100917431192662\n",
      "recal score  0.21100917431192662\n",
      "acc score    0.21100917431192662\n",
      "epoch number 80 loss = 0.05861922353506088 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7242edcd6f3476f9545159c88cd2303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 81 loss = 0.0770292580127716 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8acd5eab04461dbf637e1a7f4bdfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 82 loss = 0.07610224187374115 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff6a0ee89004ff3b1b9223b8ff04a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 83 loss = 0.08565468341112137 with lr = [0.00025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19faaac3107e4d018826d26d259b951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 84 loss = 0.07989242672920227 with lr = [0.000125]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a0a13dade247c0b0cc954a966a3104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 85 loss = 0.07375454157590866 with lr = [0.000125]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535348a67f734fa0a88700a0da916482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 86 loss = 0.07370564341545105 with lr = [0.000125]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2582dee70fa64f33a7db21e49e6de5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 87 loss = 0.07080606371164322 with lr = [0.000125]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d1eb254b554fb79613441677e2d528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 88 loss = 0.07023243606090546 with lr = [6.25e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acc31f651c04336b7ceb0e35fd24f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 89 loss = 0.07829870283603668 with lr = [6.25e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f621dfdbc54876bc481ce0f400c2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa5ee45178c4dd09a7d4ce80e025d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78980c93693d43f487bfd69b559050b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd5bbcfcf594acc8171d9717ec7a46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.22018348623853212\n",
      "recal score  0.22018348623853212\n",
      "acc score    0.22018348623853212\n",
      "epoch number 90 loss = 0.08091691881418228 with lr = [6.25e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a63bd57343b44318078fefc198d3c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 91 loss = 0.07965318113565445 with lr = [6.25e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1898f088cd4e492aa4830716a81d7bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 92 loss = 0.06710518896579742 with lr = [3.125e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c504006d0a4d8f9103fe025cb3b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 93 loss = 0.06784216314554214 with lr = [3.125e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5308059d6c248cc9c440a63ba710273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 94 loss = 0.07235758006572723 with lr = [3.125e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455fb483ec084cb6bfaf7f34b3f63b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 95 loss = 0.08056341111660004 with lr = [3.125e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba35cf0fbde3471985713131179387fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 96 loss = 0.07214254885911942 with lr = [1.5625e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7a1acf278e48fab53c6ff1b98c7306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 97 loss = 0.0775526612997055 with lr = [1.5625e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e594a56b85403398fe83d433fc0679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 98 loss = 0.07458005100488663 with lr = [1.5625e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93918d7d61c54d47a5e53ad01c325f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 99 loss = 0.06459430605173111 with lr = [1.5625e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fac7611d96445dd9ad888fe02d68687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_24980\\3856375562.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df4a07ef4d64d70a2eb73fd654e291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bcc369b79e4156a8d0acedc41d344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ac278798e346a89d49027f875be1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.21100917431192662\n",
      "recal score  0.21100917431192662\n",
      "acc score    0.21100917431192662\n",
      "epoch number 100 loss = 0.07871158421039581 with lr = [7.8125e-06]\n",
      "best loss at epoch = 80 with 0.05861922353506088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch = 100\n",
    "lr = 2e-3\n",
    "chunk = 50\n",
    "e = 0\n",
    "best_loss = 0\n",
    "path_save = \"../Sign_Language_Detection/model/Version1\"\n",
    "num_still = 0\n",
    "sigoid_state = False\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=base_df)\n",
    "\n",
    "\n",
    "len_output = train_dataset.len_answer()\n",
    "len_input = train_dataset.data_info()[-2]\n",
    "train_dataset = DataLoader(train_dataset,batch_size=batch_size)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#   lstm = cnn_lstm(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output).to(\"cuda\")\n",
    "# else:\n",
    "#   lstm = cnn_lstm(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  lstm = CNNTimeSeriesClassifier((chunk,len_input),len_output,dropout=0.4).to(\"cuda\")\n",
    "else:\n",
    "  lstm = CNNTimeSeriesClassifier((chunk,len_input),len_output,dropout=0.4)\n",
    "# patch_len = 10\n",
    "# stride = 10\n",
    "# d_model = 64\n",
    "# hidden_dim = 128\n",
    "\n",
    "# lstm = PLSTM(len_input, patch_len, stride, d_model, hidden_dim, len_output)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(),lr=lr,weight_decay=0.0001)\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',patience =3  ,min_lr = 5e-6,factor=0.5)\n",
    "print(f\" data train = {int(len(train_dataset)*batch_size)} with {len_input} feature\")\n",
    "\n",
    "\n",
    "n = 0\n",
    "for param in lstm.parameters():\n",
    "  param.requires_grad=True\n",
    "lstm.train()\n",
    "\n",
    "for k in range(1,epoch+1):\n",
    "    loss_total = 0\n",
    "    data_answer = []\n",
    "    for inputs,answer in tqdm(train_dataset):\n",
    "      # answer = answer[0]\n",
    "      data_answer.append(answer)\n",
    "      output = lstm(inputs)\n",
    "      optimizer.zero_grad()\n",
    "      if torch.argmax(answer).item() != torch.argmax(output).item():\n",
    "        loss = criterion(output,answer)\n",
    "      else:\n",
    "        loss = criterion(output,answer)\n",
    "      \n",
    "      \n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_total += loss\n",
    "      n+=1\n",
    "        \n",
    "    if best_loss == 0 or best_loss > loss_total/len(train_dataset):\n",
    "      best_loss = loss_total/len(train_dataset)\n",
    "      state_dict = lstm.state_dict()\n",
    "      e = k\n",
    "      num_still = 0\n",
    "    else:\n",
    "      num_still +=1\n",
    "      \n",
    "    scheduler.step(loss_total/len(train_dataset))\n",
    "    num_still = 0\n",
    "    if num_still >= 3:\n",
    "      print(\"step up to learning = \",scheduler.get_last_lr())\n",
    "      break\n",
    "  \n",
    "  \n",
    "    if k% 10==0 and k!=0:\n",
    "      import glob\n",
    "      import os\n",
    "\n",
    "\n",
    "\n",
    "      test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "      # test_df  = test_df[test_df.columns[1:]]\n",
    "      test_dataset = CustomDataset(\"collect_data/20250624_131408_พชชาภา24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=test_df)\n",
    "      test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "      y_pred = []\n",
    "      y_true = []\n",
    "      prob_x = []\n",
    "      prob_y = []\n",
    "      with torch.no_grad():\n",
    "          for inputs,answer in tqdm(test_dataset):\n",
    "              output = lstm(inputs)\n",
    "              prob_x.append(output)\n",
    "              prob_y.append(answer)\n",
    "              y_pred += (torch.argmax(output,dim=1)).tolist()\n",
    "              y_true += (torch.argmax(answer,dim=1)).tolist()\n",
    "                  \n",
    "                \n",
    "      from sklearn.metrics import f1_score,recall_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "      f1_scores = f1_score(y_true, y_pred, average=\"micro\")\n",
    "      print(\"f1 score    \",f1_scores)\n",
    "      recall_scores = recall_score(y_true, y_pred, average=\"micro\")\n",
    "      print(\"recal score \",recall_scores)\n",
    "      acc = accuracy_score(y_true, y_pred)\n",
    "      print(\"acc score   \",acc)\n",
    "      # cnf = confusion_matrix(y_true, y_pred)  \n",
    "    \n",
    "      \n",
    "    \n",
    "    print(f\"epoch number {k} loss = {loss_total/len(train_dataset)} with lr = {scheduler.get_last_lr()}\")\n",
    "print(f\"best loss at epoch = {e} with {best_loss}\")\n",
    "torch.save(state_dict,f\"{path_save}/model_epoch_{e}_croc.pt\")\n",
    "torch.save(lstm, r\"./model/Version1/finalmodel_croc.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b88db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10752/5376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22804\\313000124.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e17f191de4a9b8b66a8a892a05cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894449a1227940c0bf3b1567b21d6154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da520fde5076452081ed40fcfa6ee36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "# test_df  = test_df[test_df.columns[1:]]\n",
    "test_dataset = CustomDataset(\"collect_data/20250624_131408_พชชาภา24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=test_df)\n",
    "test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "prob_x = []\n",
    "prob_y = []\n",
    "with torch.no_grad():\n",
    "    for inputs,answer in tqdm(test_dataset):\n",
    "        output = lstm(inputs)\n",
    "        prob_x.append(output)\n",
    "        prob_y.append(answer)\n",
    "        y_pred += (torch.argmax(output,dim=1)).tolist()\n",
    "        y_true += (torch.argmax(answer,dim=1)).tolist()\n",
    "            \n",
    "          \n",
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "f1_scores = f1_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"f1 score    \",f1_scores)\n",
    "recall_scores = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"recal score \",recall_scores)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"acc score   \",acc)\n",
    "# cnf = confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202f260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.5596330275229358\n",
      "recal score  0.5596330275229358\n",
      "acc score    0.5596330275229358\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cnf,)\n",
    "# disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8143562c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4457)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cros = nn.CrossEntropyLoss()\n",
    "cros(prob_x[0],prob_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e19f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error pred --> true\n",
      "0\n",
      "22 --> 22\n",
      "tensor(3.4457)\n",
      "2\n",
      "7 --> 7\n",
      "tensor(3.5548)\n",
      "8\n",
      "48 --> 48\n",
      "tensor(3.1257)\n",
      "9\n",
      "49 --> 49\n",
      "tensor(3.4847)\n",
      "11\n",
      "53 --> 53\n",
      "tensor(3.0907)\n",
      "12\n",
      "57 --> 57\n",
      "tensor(3.0946)\n",
      "13\n",
      "46 --> 46\n",
      "tensor(3.1409)\n",
      "14\n",
      "29 --> 29\n",
      "tensor(3.2538)\n",
      "15\n",
      "11 --> 11\n",
      "tensor(3.0932)\n",
      "16\n",
      "6 --> 6\n",
      "tensor(3.1041)\n",
      "17\n",
      "52 --> 52\n",
      "tensor(3.1209)\n",
      "18\n",
      "10 --> 10\n",
      "tensor(3.6265)\n",
      "19\n",
      "14 --> 14\n",
      "tensor(3.0918)\n",
      "22\n",
      "4 --> 4\n",
      "tensor(3.1073)\n",
      "25\n",
      "18 --> 18\n",
      "tensor(3.0905)\n",
      "26\n",
      "13 --> 13\n",
      "tensor(3.0896)\n",
      "27\n",
      "9 --> 9\n",
      "tensor(3.0898)\n",
      "30\n",
      "21 --> 21\n",
      "tensor(3.0953)\n",
      "31\n",
      "37 --> 37\n",
      "tensor(3.0897)\n",
      "33\n",
      "12 --> 12\n",
      "tensor(3.1316)\n",
      "34\n",
      "15 --> 15\n",
      "tensor(3.0924)\n",
      "35\n",
      "44 --> 44\n",
      "tensor(3.2189)\n",
      "36\n",
      "34 --> 34\n",
      "tensor(3.1394)\n",
      "37\n",
      "27 --> 27\n",
      "tensor(3.1244)\n",
      "38\n",
      "54 --> 54\n",
      "tensor(3.0897)\n",
      "39\n",
      "5 --> 5\n",
      "tensor(3.0898)\n",
      "40\n",
      "36 --> 36\n",
      "tensor(3.1135)\n",
      "41\n",
      "19 --> 19\n",
      "tensor(3.0903)\n",
      "42\n",
      "23 --> 23\n",
      "tensor(3.0902)\n",
      "43\n",
      "40 --> 40\n",
      "tensor(3.0897)\n",
      "44\n",
      "32 --> 32\n",
      "tensor(3.1473)\n",
      "46\n",
      "56 --> 56\n",
      "tensor(3.1867)\n",
      "47\n",
      "35 --> 35\n",
      "tensor(3.5737)\n",
      "49\n",
      "22 --> 22\n",
      "tensor(3.1893)\n",
      "57\n",
      "49 --> 49\n",
      "tensor(3.0977)\n",
      "58\n",
      "51 --> 51\n",
      "tensor(3.1094)\n",
      "59\n",
      "53 --> 53\n",
      "tensor(3.1270)\n",
      "60\n",
      "57 --> 57\n",
      "tensor(3.0899)\n",
      "62\n",
      "29 --> 29\n",
      "tensor(3.1222)\n",
      "64\n",
      "6 --> 6\n",
      "tensor(3.0952)\n",
      "65\n",
      "52 --> 52\n",
      "tensor(3.1162)\n",
      "67\n",
      "14 --> 14\n",
      "tensor(3.2621)\n",
      "73\n",
      "18 --> 18\n",
      "tensor(3.0897)\n",
      "74\n",
      "13 --> 13\n",
      "tensor(3.3498)\n",
      "75\n",
      "9 --> 9\n",
      "tensor(3.0910)\n",
      "77\n",
      "50 --> 50\n",
      "tensor(3.4597)\n",
      "78\n",
      "21 --> 21\n",
      "tensor(3.1008)\n",
      "79\n",
      "37 --> 37\n",
      "tensor(3.0906)\n",
      "81\n",
      "12 --> 12\n",
      "tensor(3.4461)\n",
      "82\n",
      "15 --> 15\n",
      "tensor(3.1348)\n",
      "83\n",
      "44 --> 44\n",
      "tensor(3.6097)\n",
      "84\n",
      "34 --> 34\n",
      "tensor(3.5631)\n",
      "85\n",
      "27 --> 27\n",
      "tensor(3.1100)\n",
      "86\n",
      "54 --> 54\n",
      "tensor(3.0896)\n",
      "87\n",
      "5 --> 5\n",
      "tensor(3.0897)\n",
      "88\n",
      "36 --> 36\n",
      "tensor(3.1146)\n",
      "89\n",
      "19 --> 19\n",
      "tensor(3.0980)\n",
      "90\n",
      "42 --> 42\n",
      "tensor(3.1623)\n",
      "91\n",
      "23 --> 23\n",
      "tensor(3.0959)\n",
      "92\n",
      "40 --> 40\n",
      "tensor(3.0897)\n",
      "93\n",
      "32 --> 32\n",
      "tensor(3.3882)\n",
      "95\n",
      "56 --> 56\n",
      "tensor(3.4478)\n",
      "98\n",
      "0 --> 0\n",
      "tensor(3.0896)\n",
      "99\n",
      "0 --> 0\n",
      "tensor(3.0907)\n",
      "100\n",
      "0 --> 0\n",
      "tensor(3.0899)\n",
      "101\n",
      "0 --> 0\n",
      "tensor(3.0899)\n",
      "102\n",
      "0 --> 0\n",
      "tensor(3.0898)\n",
      "103\n",
      "0 --> 0\n",
      "tensor(3.1387)\n",
      "104\n",
      "0 --> 0\n",
      "tensor(3.0898)\n",
      "105\n",
      "0 --> 0\n",
      "tensor(3.0897)\n",
      "106\n",
      "0 --> 0\n",
      "tensor(3.1212)\n",
      "107\n",
      "0 --> 0\n",
      "tensor(3.1056)\n",
      "108\n",
      "0 --> 0\n",
      "tensor(3.0913)\n"
     ]
    }
   ],
   "source": [
    "print(\"error pred --> true\")\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]==y_true[i]:\n",
    "        print(i)\n",
    "        print(f\"{y_true[i]} --> {y_pred[i]}\")\n",
    "        print(cros(prob_x[i],prob_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705cc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, input_shape, n_classes, dropout=0.3):\n",
    "        \"\"\"\n",
    "        CNN-based Time Series Classifier following your architecture diagram\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Tuple (sequence_length, n_features) - e.g., (121, 21)\n",
    "            n_classes: Number of output classes\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(CNNTimeSeriesClassifier, self).__init__()\n",
    "        \n",
    "        seq_len, n_features = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_rate = dropout\n",
    "        \n",
    "        # Input normalization layer\n",
    "        self.normalization = nn.BatchNorm1d(n_features)\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch, channels, height, width)\n",
    "        # We'll treat sequence as height and features as width, with 1 channel\n",
    "        # Input shape: (None, 1, seq_len, n_features) - e.g., (None, 1, 121, 21)\n",
    "        # First Conv2D block\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, \n",
    "            out_channels=32, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after first conv+pool\n",
    "        # After conv1: (None, 32, 121, 21) -> (None, 32, 119, 19) with padding=1\n",
    "        # After pool1: (None, 32, 119, 19) -> (None, 32, 59, 9)\n",
    "        h1, w1 = seq_len // 2, n_features // 2\n",
    "        \n",
    "        # Second Conv2D block\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after second conv+pool\n",
    "        # After conv2: (None, 64, 59, 9) -> (None, 64, 57, 7) with padding=1\n",
    "        # After pool2: (None, 64, 57, 7) -> (None, 64, 28, 3)\n",
    "        h2, w2 = h1 // 2, w1 // 2\n",
    "        \n",
    "        # Third Conv2D block\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        # Calculate final conv output shape\n",
    "        # After conv3: (None, 64, 28, 3) -> (None, 64, 26, 1) with padding=1\n",
    "        h3, w3 = h2, w2\n",
    "        \n",
    "        # Calculate flattened size dynamically\n",
    "        self.flatten_size = 64 * h3 * w3\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 64)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "        # Activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights properly\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, n_features)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Normalize along feature dimension\n",
    "        # Reshape for BatchNorm1d: (batch_size * seq_len, n_features)\n",
    "        x_norm = x.view(-1, x.size(2))\n",
    "        x_norm = self.normalization(x_norm)\n",
    "        x = x_norm.view(batch_size, x.size(1), x.size(2))\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch_size, 1, seq_len, n_features)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # First Conv2D + MaxPool2D\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second Conv2D + MaxPool2D\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Third Conv2D\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # First Dense layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Dense layer (output)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return model configuration for saving\"\"\"\n",
    "        return {\n",
    "            'input_shape': self.input_shape,\n",
    "            'n_classes': self.n_classes,\n",
    "            'dropout': self.dropout_rate,\n",
    "            'flatten_size': self.flatten_size\n",
    "        }\n",
    "dicta = torch.load(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\cnn_timeseries_model_20250803_120029.pth\",weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d1b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNTimeSeriesClassifier((50,28),51,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e12522d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTimeSeriesClassifier(\n",
       "  (normalization): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=5376, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=51, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(dicta[\"model_state_dict\"])\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTimeSeriesClassifier(\n",
       "  (normalization): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=5376, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=51, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\finalmodel_86.pt\",weights_only=False)\n",
    "# model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcdaa753",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, r\"./model/model_96.pt\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2060ae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTimeSeriesClassifier(\n",
       "  (normalization): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=5376, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=51, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(r\"./model/model_96.pt\",weights_only=False)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2db433f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path,\n",
    "                 batch=16,\n",
    "                 chunk = 100,\n",
    "                 vocab_path = \"../Sign_Language_Detection/label.json\",\n",
    "                table:bool = False,\n",
    "                dataframe=None):\n",
    "        \n",
    "        \n",
    "        with open(vocab_path,\"r\") as f:\n",
    "            compare = json.load(f)\n",
    "        self.vocab = len(compare)\n",
    "        \n",
    "        if not table:\n",
    "            self._data_csv = pd.read_csv(csv_path)\n",
    "        else:\n",
    "            self._data_csv = dataframe\n",
    "        \n",
    "        \n",
    "        self._data_csv = self._data_csv[~(self._data_csv.Label.isin([ \"cooldown\",\"error_redo\",\"break_time\",]))]\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self._data_csv[\"Label\"] = self.label_encoder.fit_transform(self._data_csv[\"Label\"])\n",
    "        # self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
    "        self._data_csv = self._data_csv.drop(columns=[\"timestamp_ms\"])\n",
    "        self.train_data,self.answer_transform = self.convert_data_csv_train(self._data_csv,compare,segment=chunk,range_data=30)\n",
    "        print(self.answer_transform)\n",
    "        self.train_data = torch.tensor([i.tolist() for i in self.train_data])\n",
    "        self.n_classes = len(self.label_encoder.classes_)\n",
    "        \n",
    "        \n",
    "        # for i in range(0,len(self.train_data)):\n",
    "        #     # print(self.train_data)\n",
    "            \n",
    "            \n",
    "        #     # dummy = torch.zeros(self.vocab)\n",
    "        #     # ct = Counter(self.train_data[i][:,-1].tolist()).most_common()\n",
    "        #     # if len(ct) == 2 and ct[0][0] ==0:\n",
    "        #     #     idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[1]\n",
    "        #     # else:\n",
    "        #     #     idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[0]\n",
    "        #     # print(Counter(self.train_data[i][:,-1].tolist()).most_common())\n",
    "\n",
    "        #     # dummy[int(idx)] = 1\n",
    "        #     label = Counter(self.train_data[i][:,-1].tolist()).most_common(1)[0][0]\n",
    "        #     self.answer_transform.append(torch.tensor(label))\n",
    "        \n",
    "        # self.train_data = self.train_data[:,:,:-1]\n",
    "        self.nums,self.segment,self.input = self.train_data.size()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.train_data[index]\n",
    "        answer = self.answer_transform[index]\n",
    "        # print(answer)\n",
    "        if torch.cuda.is_available():\n",
    "            return inputs.to(torch.float32).to(\"cuda\"),answer.to(\"cuda\")\n",
    "        else:\n",
    "            return inputs.to(torch.float32),answer\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def len_answer(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def data_info(self):\n",
    "        return self.nums,self.segment,self.input,self.train_data\n",
    "    \n",
    "    def get_label_encoder(self):\n",
    "        return self.label_encoder\n",
    "    \n",
    "    def convert_data_csv_train(self,data,compare,segment=50,range_data = 0):\n",
    "\n",
    "\n",
    "        answer_transform = []\n",
    "        datas = []\n",
    "        \n",
    "        data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n",
    "        grouped_dfs = [g.drop(columns='group_id') for _, g in data.groupby('group_id')]\n",
    "        # grop_label = [g.drop(columns='group_id')[\"Label\"].values for _, g in data.groupby('group_id')]\n",
    "        \n",
    "        print(\"len(data): \",len(grouped_dfs))\n",
    "        print(\"filter Value\")\n",
    "        # all_data = []\n",
    "        # for i in tqdm(grouped_dfs,total = len(grouped_dfs)):\n",
    "        #     if len(i) > range_data:\n",
    "        #         all_data.append(i)\n",
    "\n",
    "        valid_groups = [group for group in grouped_dfs if len(group) >= range_data]\n",
    "        \n",
    "        \n",
    "        for group in tqdm(valid_groups,total = len(valid_groups)):\n",
    "            feature = group.drop(columns = \"Label\").values\n",
    "            label = Counter(group[\"Label\"].values).most_common(1)[0][0]\n",
    "            answer_transform.append(torch.tensor(label))\n",
    "        \n",
    "        \n",
    "\n",
    "            # print(\"pad&mean Value\")\n",
    "\n",
    "            # real = []\n",
    "            # for i in tqdm(all_data,total = len(all_data)):\n",
    "            segment = segment\n",
    "            if len(feature) < segment:\n",
    "                tensor_df = (torch.tensor(feature))\n",
    "                n,b = tensor_df.size()\n",
    "                sequence = torch.nn.functional.pad(tensor_df, pad=(0, 0, 0,segment-n), mode='constant', value=0)\n",
    "\n",
    "            else:\n",
    "                indices = np.linspace(0, len(feature)-1, 50, dtype=int)\n",
    "                # print(feature)\n",
    "                sequence = feature[indices]\n",
    "                \n",
    "                # step = int(np.ceil(len(i)//segment))\n",
    "                # temp = []\n",
    "                # for k in range(segment):\n",
    "                #     temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "                # real.append(sequence)\n",
    "            \n",
    "            datas.append(sequence) \n",
    "                \n",
    "                \n",
    "        print(len(datas),len(answer_transform))\n",
    "        # train_data =\n",
    "        return  torch.tensor(datas),torch.tensor(answer_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de77979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 label groups\n",
      "Kept 114 groups after length filtering\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85954e2ed4424cf7953799e030207dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing sequences:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created: 114 sequences of shape torch.Size([114, 50, 28])\n",
      "Classes: 51, Distribution: Counter({0: 16, 6: 2, 5: 2, 3: 2, 42: 2, 10: 2, 50: 2, 24: 2, 21: 2, 7: 2, 12: 2, 25: 2, 13: 2, 23: 2, 36: 2, 37: 2, 18: 2, 45: 2, 39: 2, 31: 2, 9: 2, 29: 2, 49: 2, 44: 2, 28: 2, 33: 2, 30: 2, 22: 2, 41: 2, 20: 2, 48: 2, 40: 2, 19: 2, 35: 2, 1: 2, 32: 2, 47: 2, 26: 2, 46: 2, 11: 2, 15: 2, 17: 2, 4: 2, 34: 2, 8: 2, 27: 2, 38: 2, 43: 2, 14: 2, 2: 1, 16: 1})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4e4aea95f64ac8aa81480cc11abadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.8859649122807017\n",
      "recal score  0.8859649122807017\n",
      "acc score    0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "torch.manual_seed(402)\n",
    "model.eval()\n",
    "\n",
    "chunk = 50\n",
    "test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "# test_df  = test_df[test_df.columns[1:]]\n",
    "test_dataset = ImprovedCustomDataset(test_df,50,min_sequence_length=30,zero_ratio=0,down_zero=False)\n",
    "test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "prob_x = []\n",
    "prob_y = []\n",
    "with torch.no_grad():\n",
    "    for inputs,answer in tqdm(test_dataset):\n",
    "        output = model(inputs.to(\"cuda\"))\n",
    "        prob_x.append(output)\n",
    "        prob_y.append(answer)\n",
    "        y_pred += (torch.argmax(output,dim=1)).tolist()\n",
    "        y_true += answer.numpy().tolist()\n",
    "        \n",
    "          \n",
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "f1_scores = f1_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"f1 score    \",f1_scores)\n",
    "recall_scores = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"recal score \",recall_scores)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"acc score   \",acc)\n",
    "cnf = confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32f7e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnfusion = ConfusionMatrixDisplay(confusion_matrix =cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb7f5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c8be24ee60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "cnfusion.plot(include_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7583086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nothing', 'nothing', 'nothing', ..., 'nothing', 'nothing',\n",
       "       'nothing'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f66a6fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHybridmodel-project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSign_Language_Detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcollect_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m20250715_111750_DATA_INDICATOR_sensor.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# test_df  = test_df[test_df.columns[1:]]\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollect_data/20250624_131408_พชชาภา24062025_sensor.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,vocab_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Sign_Language_Detection/label.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,chunk\u001b[38;5;241m=\u001b[39mchunk,table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dataframe\u001b[38;5;241m=\u001b[39mtest_df)\n\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m y_pred1 \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CustomDataset' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "# test_df  = test_df[test_df.columns[1:]]\n",
    "test_dataset = CustomDataset(\"collect_data/20250624_131408_พชชาภา24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=test_df)\n",
    "test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "y_pred1 = []\n",
    "y_true1 = []\n",
    "prob_x = []\n",
    "prob_y = []\n",
    "with torch.no_grad():\n",
    "    for inputs2,answer in tqdm(test_dataset):\n",
    "        output = model(inputs2)\n",
    "        prob_x.append(output)\n",
    "        prob_y.append(answer)\n",
    "        y_pred1 += (torch.argmax(output,dim=1)).tolist()\n",
    "        # y_true1 += (torch.argmax(answer,dim=0)).tolist()\n",
    "        y_true1 += [answer.item()]\n",
    "            \n",
    "          \n",
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "f1_scores = f1_score(y_true1, y_pred1, average=\"micro\")\n",
    "print(\"f1 score    \",f1_scores)\n",
    "recall_scores = recall_score(y_true1, y_pred1, average=\"micro\")\n",
    "print(\"recal score \",recall_scores)\n",
    "acc = accuracy_score(y_true1, y_pred1)\n",
    "print(\"acc score   \",acc)\n",
    "# cnf = confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6ef8d",
   "metadata": {},
   "source": [
    "# How to use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b5a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_csv_train(data,segment=50):\n",
    "\n",
    "    real = []\n",
    "    for i in tqdm(data,total = len(data)):\n",
    "        segment = segment\n",
    "        if len(i) < segment:\n",
    "            # tensor_df = (torch.tensor(i.clone()))\n",
    "            tensor_df = i.clone()\n",
    "            n,b = tensor_df.size()\n",
    "            padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, segment-n, 0), mode='constant', value=0)\n",
    "            # print(padded_tensor.size())\n",
    "            real.append(padded_tensor.tolist())\n",
    "        else:\n",
    "            step = int(np.ceil(len(i)//segment))\n",
    "            temp = []\n",
    "            for k in range(segment):\n",
    "                temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "            real.append(temp)\n",
    "    return torch.tensor(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c441d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r\"./model/Version1/finalmodel.pt\",weights_only=False)\n",
    "with open(r\"rollback.json\",'r') as f:\n",
    "    vocap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aad08ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11982\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.DataFrame()\n",
    "for i in glob.glob(r\"./collect_data/new_data/*\"):\n",
    "    df = pd.read_csv(rf\"{i}\")\n",
    "    base_df = pd.concat([base_df,df])\n",
    "    break\n",
    "print(len(base_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ac6fad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = torch.load(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\finalmodel_86.pt\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3612a64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTimeSeriesClassifier(\n",
       "  (normalization): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=5376, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=51, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e397707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ee2a6e86e946d0be5e2e1bd7189f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.rand(1,29)\n",
    "datas = torch.rand(1,29)\n",
    "i=0\n",
    "while i<20:\n",
    "    \n",
    "    ### you need to put a streaming inout here\n",
    "    \n",
    "    \n",
    "    datas = torch.concat([datas,data])\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "datas = datas[1:,:]\n",
    "\n",
    "### input must be [chunk,feature] --> [x,29]\n",
    "tas = convert_data_csv_train(datas.unsqueeze(0))\n",
    "tas = tas.movedim(1,2)\n",
    "answer = torch.argmax(model(tas))\n",
    "finalans = vocap[str(answer.item())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df8879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "chunk_size = 50\n",
    "features = torch.rand(30,28)\n",
    "sequences = []\n",
    "if len(features) >= 50:\n",
    "    # If longer than chunk_size, use uniform sampling\n",
    "    indices = np.linspace(0, len(features)-1, chunk_size, dtype=int)\n",
    "    sequence = features[indices]\n",
    "else:\n",
    "    # If shorter, pad with zeros at the end\n",
    "    sequence = np.zeros((chunk_size, features.shape[1]))\n",
    "    sequence[:len(features)] = features\n",
    "\n",
    "sequences.append(sequence)\n",
    "# labels.append(most_common_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e1b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5b325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wayupuk sommuang\\aida\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\cnn_timeseries_model_20250803_120029.pth\",weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d19ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_state_dict': OrderedDict([('normalization.weight',\n",
       "               tensor([0.9368, 1.0048, 0.9357, 0.9360, 1.0072, 0.9416, 0.8587, 0.8866, 0.9098,\n",
       "                       0.9012, 0.9464, 0.9348, 0.7739, 0.6852, 1.0935, 0.9764, 1.0977, 1.1291,\n",
       "                       1.2618, 1.2244, 0.9526, 1.0216, 0.8541, 1.0645, 1.0574, 1.0971, 1.0129,\n",
       "                       1.2894], device='cuda:0')),\n",
       "              ('normalization.bias',\n",
       "               tensor([-0.0565, -0.0850, -0.1522, -0.0644, -0.0521,  0.0517, -0.0049,  0.0787,\n",
       "                        0.1080,  0.0714, -0.0971,  0.0076,  0.0657, -0.0166,  0.0871,  0.0297,\n",
       "                       -0.1515, -0.1185, -0.0374,  0.1313,  0.1707,  0.0885,  0.0428,  0.1231,\n",
       "                       -0.0491, -0.0695, -0.0235, -0.0912], device='cuda:0')),\n",
       "              ('normalization.running_mean',\n",
       "               tensor([-6.7445e-01, -6.0989e+00, -5.3089e+00, -2.3383e-02,  3.4808e-02,\n",
       "                       -1.6581e-02, -4.0500e+01, -4.7012e+00,  1.2256e+02,  1.3272e+02,\n",
       "                        8.5071e+01,  8.7488e+01,  8.1434e+01,  7.3402e+01, -5.5512e-01,\n",
       "                        3.6162e+00, -6.1450e+00, -1.9099e-01,  9.7963e-02,  2.3132e-02,\n",
       "                        2.4422e+01, -5.6136e+00,  1.3217e+02,  1.9588e+02,  1.1314e+02,\n",
       "                        1.3289e+02,  1.4234e+02,  1.0461e+02], device='cuda:0')),\n",
       "              ('normalization.running_var',\n",
       "               tensor([5.5363e+00, 5.0848e+00, 1.7071e+01, 1.0768e+00, 6.0215e-01, 6.6178e-01,\n",
       "                       2.6041e+02, 2.3795e+02, 1.2275e+03, 3.8037e+04, 4.2481e+04, 4.6087e+04,\n",
       "                       3.9996e+04, 3.6939e+04, 1.1159e+01, 1.4216e+01, 1.8092e+01, 1.8540e+00,\n",
       "                       1.5777e+00, 1.6653e+00, 6.6725e+02, 5.4390e+02, 1.4304e+03, 4.9755e+04,\n",
       "                       5.3330e+04, 7.1996e+04, 7.3528e+04, 5.0028e+04], device='cuda:0')),\n",
       "              ('normalization.num_batches_tracked',\n",
       "               tensor(6292, device='cuda:0')),\n",
       "              ('conv1.weight',\n",
       "               tensor([[[[-6.1205e-02,  3.8075e-02, -9.1391e-02],\n",
       "                         [-1.0372e-01,  2.9737e-02, -8.6156e-02],\n",
       "                         [-1.2513e-01,  6.3137e-02, -3.5673e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.3010e-02,  6.7009e-02, -1.7464e-01],\n",
       "                         [ 1.3594e-03,  2.4132e-01, -1.2031e-01],\n",
       "                         [-4.3631e-02, -1.7227e-01,  7.1454e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.7402e-02, -1.2742e-01,  1.3936e-01],\n",
       "                         [ 2.6680e-02, -1.6786e-01,  2.7682e-01],\n",
       "                         [ 7.2857e-03, -1.3763e-01,  5.7352e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.5385e-02,  1.0230e-01, -6.0249e-02],\n",
       "                         [-2.1691e-02, -1.4378e-02, -6.3880e-02],\n",
       "                         [ 3.7470e-02, -5.9076e-02, -5.4954e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7832e-01, -1.8497e-01,  1.9379e-01],\n",
       "                         [ 7.3942e-02, -3.8542e-02,  6.0532e-02],\n",
       "                         [-2.4395e-01,  1.8039e-01, -1.8215e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0721e-01,  6.5401e-02,  1.4782e-01],\n",
       "                         [-2.3774e-01, -3.1367e-02,  5.8122e-02],\n",
       "                         [-2.2652e-01, -8.0362e-02, -2.2229e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.8481e-01, -2.5855e-02, -7.9350e-02],\n",
       "                         [-7.4217e-02, -1.0704e-01, -1.8096e-02],\n",
       "                         [ 1.4352e-01,  1.7367e-01, -1.7622e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1900e-01, -1.2966e-01, -1.5013e-01],\n",
       "                         [ 1.6367e-01, -9.5168e-02, -6.2617e-02],\n",
       "                         [-1.5014e-01,  2.0850e-01,  1.9486e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.7982e-02, -1.5353e-01, -2.7223e-01],\n",
       "                         [-2.4396e-01, -1.2664e-01,  6.0517e-03],\n",
       "                         [ 2.2989e-02,  5.0678e-02,  1.4307e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1602e-01, -1.7322e-01, -6.7387e-02],\n",
       "                         [-3.0911e-01, -1.9227e-01,  5.4683e-02],\n",
       "                         [ 1.3384e-01, -1.4533e-01,  2.7593e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5395e-02,  4.7418e-02,  8.0499e-02],\n",
       "                         [ 9.9428e-02,  1.1119e-01,  1.3232e-01],\n",
       "                         [ 1.4712e-01,  6.7719e-02,  1.6539e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.4684e-02,  1.0463e-02,  4.9018e-02],\n",
       "                         [-1.4575e-02,  6.2286e-02, -5.9439e-03],\n",
       "                         [-8.9120e-02, -2.9435e-02,  2.3850e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2058e-03,  1.0907e-01, -1.6679e-01],\n",
       "                         [ 2.4879e-02,  2.6983e-01, -7.6776e-02],\n",
       "                         [-1.0293e-01,  1.9914e-01, -6.2745e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5104e-02,  5.2674e-02, -9.5750e-02],\n",
       "                         [-2.7857e-02, -4.7848e-02, -3.5238e-02],\n",
       "                         [ 1.3711e-02, -1.0370e-01,  1.3526e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6260e-01,  9.3444e-02, -5.5240e-02],\n",
       "                         [ 3.1287e-02,  3.6550e-02,  9.7388e-03],\n",
       "                         [ 6.6530e-03,  8.0909e-02,  2.0339e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.0536e-02,  9.0365e-02, -2.8463e-02],\n",
       "                         [-7.1731e-02,  1.3491e-01,  1.8475e-01],\n",
       "                         [ 9.6191e-04,  3.5395e-02, -1.2044e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9242e-02,  3.0354e-02,  5.8481e-02],\n",
       "                         [ 6.1138e-02, -3.2993e-02,  1.3793e-02],\n",
       "                         [ 5.6475e-02,  5.1083e-02,  9.6966e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4115e-01, -9.4802e-02,  9.1053e-02],\n",
       "                         [ 8.2254e-02,  2.9906e-02, -7.0124e-02],\n",
       "                         [ 7.0031e-02,  1.1158e-01, -8.9629e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.8416e-02, -2.2045e-02,  6.1805e-02],\n",
       "                         [ 6.8530e-02,  3.2630e-02,  1.7498e-01],\n",
       "                         [-1.5588e-01,  6.4047e-02,  9.1949e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1903e-01, -8.1283e-02, -2.4972e-02],\n",
       "                         [ 1.0167e-02,  2.2770e-01,  5.7256e-02],\n",
       "                         [ 3.8464e-02,  1.3080e-01,  1.0136e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0488e-01,  1.2192e-01, -6.5828e-02],\n",
       "                         [ 1.5625e-01,  1.0624e-01, -1.2928e-01],\n",
       "                         [-1.6899e-03,  5.4862e-03, -7.4017e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.5287e-01,  5.9385e-02, -1.8193e-01],\n",
       "                         [-5.5987e-02,  1.7725e-02, -1.0122e-01],\n",
       "                         [-4.1256e-02,  7.1619e-02, -7.1698e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5606e-02, -3.9608e-02, -1.5440e-01],\n",
       "                         [ 2.7908e-01, -2.1833e-02,  6.5564e-03],\n",
       "                         [-2.6133e-01,  3.6238e-02, -4.3459e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.8357e-02, -6.2362e-02, -1.4915e-01],\n",
       "                         [ 2.2073e-01, -1.9455e-01, -1.7669e-03],\n",
       "                         [ 1.9921e-01, -2.6949e-02, -1.9086e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1075e-01,  1.3579e-01, -1.3439e-02],\n",
       "                         [ 1.2919e-01,  7.0758e-02, -1.1548e-01],\n",
       "                         [-1.0841e-01, -1.9590e-01,  3.3863e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.1410e-02, -5.6715e-02, -8.9731e-02],\n",
       "                         [ 1.2037e-02, -2.6548e-02, -5.4617e-02],\n",
       "                         [-1.0920e-01, -6.9326e-02,  2.2402e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0189e-01, -1.0614e-01, -6.0197e-02],\n",
       "                         [-3.2260e-04, -3.6488e-02,  3.9146e-02],\n",
       "                         [-5.4060e-02,  1.7763e-01, -3.9075e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.3260e-02, -6.2912e-02, -5.4211e-02],\n",
       "                         [-4.9443e-02, -1.6624e-02,  4.7623e-02],\n",
       "                         [ 9.1009e-04,  8.4104e-03, -5.9486e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8050e-01,  9.3248e-03,  1.2142e-04],\n",
       "                         [-1.5957e-02, -4.0358e-02,  9.7940e-02],\n",
       "                         [ 6.4163e-02, -5.9587e-02, -1.4387e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.5126e-02, -1.6114e-02, -5.9845e-03],\n",
       "                         [ 1.9600e-01, -1.7383e-01, -9.2940e-02],\n",
       "                         [ 8.5100e-02, -2.1651e-01,  1.7662e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.9708e-02,  4.8608e-02,  1.6193e-01],\n",
       "                         [-6.0466e-02, -1.3697e-01, -1.0243e-01],\n",
       "                         [-7.9120e-02, -3.5738e-02, -3.1007e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1854e-01, -1.6388e-01, -6.3825e-03],\n",
       "                         [-5.9465e-02,  7.3975e-03,  1.4092e-02],\n",
       "                         [-5.5747e-02,  2.2437e-02,  2.8200e-01]]]], device='cuda:0')),\n",
       "              ('conv1.bias',\n",
       "               tensor([-8.2738e-02, -6.5075e-02, -1.1319e-01, -1.0972e-02, -5.7141e-02,\n",
       "                        1.9640e-02, -9.8429e-03, -4.5256e-02,  1.9315e-02, -1.0593e-01,\n",
       "                        4.7728e-02,  4.5739e-02, -8.1355e-03, -1.7350e-02,  5.9669e-03,\n",
       "                       -7.1691e-02, -2.6276e-02, -8.4975e-05,  4.0022e-02, -8.9437e-02,\n",
       "                       -3.4259e-02, -1.0016e-01, -1.0107e-01, -8.1671e-02, -1.4261e-01,\n",
       "                       -1.1590e-01, -5.3379e-02,  1.1965e-02, -5.2095e-02, -1.2769e-01,\n",
       "                       -1.7074e-02, -8.4680e-02], device='cuda:0')),\n",
       "              ('conv2.weight',\n",
       "               tensor([[[[-8.2911e-02, -1.2743e-01, -8.7409e-03],\n",
       "                         [ 4.4337e-02, -1.1967e-02,  1.0961e-01],\n",
       "                         [-5.2166e-02, -8.9439e-02,  1.3443e-01]],\n",
       "               \n",
       "                        [[ 2.4162e-02, -3.7184e-02,  5.4180e-02],\n",
       "                         [-5.8777e-02, -1.2532e-02,  8.1204e-02],\n",
       "                         [-1.2911e-01,  6.4588e-02,  6.9328e-02]],\n",
       "               \n",
       "                        [[ 2.5700e-01, -1.5921e-01,  5.5496e-02],\n",
       "                         [ 8.4588e-02, -5.5774e-02, -5.0926e-03],\n",
       "                         [ 7.1274e-02, -1.0081e-01,  7.0215e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.6364e-01,  4.6783e-02,  8.4287e-02],\n",
       "                         [ 3.9291e-02,  1.4802e-02, -1.4726e-02],\n",
       "                         [-7.0672e-02,  4.1729e-03,  6.9973e-02]],\n",
       "               \n",
       "                        [[-1.0886e-01,  1.0064e-02, -1.4783e-02],\n",
       "                         [-7.3065e-02,  1.6495e-02, -6.1629e-02],\n",
       "                         [-1.2396e-01,  7.9834e-03, -5.6229e-02]],\n",
       "               \n",
       "                        [[-1.0908e-02, -4.3019e-02,  1.1583e-01],\n",
       "                         [ 1.2509e-02,  5.7393e-02, -1.3446e-02],\n",
       "                         [ 5.7691e-02, -6.4594e-02, -7.9036e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8630e-02, -1.0631e-01, -5.8938e-02],\n",
       "                         [ 7.9164e-02, -4.9912e-02, -8.1290e-02],\n",
       "                         [ 8.8443e-03, -1.2445e-01, -1.7117e-01]],\n",
       "               \n",
       "                        [[ 7.4175e-03,  1.2334e-01, -5.3420e-02],\n",
       "                         [-5.3882e-02,  6.1574e-02,  8.7069e-02],\n",
       "                         [-7.7887e-02,  7.1106e-02,  2.2348e-02]],\n",
       "               \n",
       "                        [[ 4.9975e-02, -5.2504e-02,  8.0634e-03],\n",
       "                         [ 1.3144e-01,  1.1509e-02,  1.3364e-01],\n",
       "                         [ 1.8145e-02, -1.4016e-02, -6.6898e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3105e-02, -6.1952e-02, -2.2341e-02],\n",
       "                         [ 7.6619e-03, -1.4979e-01,  4.3399e-02],\n",
       "                         [-1.4364e-01, -1.0257e-01, -4.3103e-02]],\n",
       "               \n",
       "                        [[ 5.9142e-02, -1.5655e-02, -4.7260e-02],\n",
       "                         [-8.7709e-02,  1.8992e-02,  2.7262e-01],\n",
       "                         [-3.1331e-02,  1.4216e-01, -1.7064e-02]],\n",
       "               \n",
       "                        [[-1.6145e-01,  9.6455e-02,  2.9254e-02],\n",
       "                         [ 4.9757e-02,  4.6318e-02,  1.0223e-01],\n",
       "                         [ 6.1611e-02, -3.5091e-02,  5.3295e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9911e-02, -1.1495e-01, -2.9448e-02],\n",
       "                         [-6.0241e-02, -2.7791e-01,  1.2090e-01],\n",
       "                         [-1.3591e-01, -1.8234e-01, -1.9015e-01]],\n",
       "               \n",
       "                        [[-2.0919e-02,  2.6081e-02, -8.7236e-02],\n",
       "                         [ 1.2100e-02, -1.3151e-01, -3.4440e-02],\n",
       "                         [-4.9098e-02, -9.1028e-02, -7.2983e-03]],\n",
       "               \n",
       "                        [[-1.8842e-01,  1.8788e-01, -5.8192e-03],\n",
       "                         [ 5.0499e-02,  1.7754e-02,  2.8263e-01],\n",
       "                         [ 3.3544e-02, -2.2055e-02,  1.2103e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.6547e-02, -3.9368e-02,  1.5524e-01],\n",
       "                         [-2.4739e-02, -7.8293e-02,  1.1065e-02],\n",
       "                         [ 8.2453e-02,  9.6635e-03,  7.8113e-02]],\n",
       "               \n",
       "                        [[-1.1302e-01, -7.4417e-02, -7.7700e-02],\n",
       "                         [ 4.3359e-02, -3.7123e-02, -1.1609e-01],\n",
       "                         [-5.9554e-03,  1.0684e-01, -4.6209e-02]],\n",
       "               \n",
       "                        [[-3.6732e-02,  5.1146e-02, -5.3799e-02],\n",
       "                         [ 3.9545e-02,  1.7911e-01,  3.3676e-02],\n",
       "                         [ 5.8439e-02,  5.0190e-02, -4.7835e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9674e-02, -9.8972e-02, -9.4700e-03],\n",
       "                         [ 1.1455e-01, -1.2843e-01, -1.6308e-02],\n",
       "                         [ 4.7758e-02, -1.3424e-01,  1.4248e-02]],\n",
       "               \n",
       "                        [[-1.2903e-01, -1.4888e-01, -8.0114e-02],\n",
       "                         [-9.7208e-02,  2.0380e-02,  7.3465e-02],\n",
       "                         [ 1.4097e-02,  4.9262e-02,  4.2153e-02]],\n",
       "               \n",
       "                        [[-1.1653e-02, -7.6799e-02,  1.1350e-01],\n",
       "                         [-4.2027e-02, -7.4648e-02,  1.6692e-01],\n",
       "                         [-8.9956e-02, -3.5920e-02,  1.1941e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7926e-02, -4.5056e-02,  6.6270e-02],\n",
       "                         [ 1.2437e-02, -2.5643e-02,  1.4869e-02],\n",
       "                         [ 6.6876e-02, -1.0373e-01,  1.1510e-01]],\n",
       "               \n",
       "                        [[ 1.0561e-01, -4.9099e-02,  2.5166e-02],\n",
       "                         [ 1.0371e-01, -6.0245e-02, -6.6042e-02],\n",
       "                         [ 1.3685e-02, -5.6291e-02,  9.4397e-02]],\n",
       "               \n",
       "                        [[-1.3941e-01, -7.1967e-02, -1.4022e-02],\n",
       "                         [-1.2205e-01, -7.6282e-02,  1.3005e-02],\n",
       "                         [-8.5756e-02, -6.8363e-02,  1.6835e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.2769e-02, -1.4857e-01, -4.9583e-02],\n",
       "                         [-5.1285e-02, -7.8820e-02, -9.1423e-02],\n",
       "                         [-1.5377e-01, -3.8755e-02, -5.1889e-02]],\n",
       "               \n",
       "                        [[-1.8773e-02, -2.0759e-02,  9.1328e-02],\n",
       "                         [-7.7524e-02,  4.1278e-02,  3.0628e-02],\n",
       "                         [-6.4262e-02,  2.0856e-02,  3.9611e-02]],\n",
       "               \n",
       "                        [[ 5.0255e-02, -1.0307e-01,  3.3597e-02],\n",
       "                         [-2.1467e-02, -2.8353e-02,  6.9649e-03],\n",
       "                         [-2.3798e-03, -1.2676e-01,  6.6460e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1282e-01,  1.4995e-01,  2.2054e-03],\n",
       "                         [ 1.0370e-01, -2.3526e-02, -1.5351e-01],\n",
       "                         [-9.7535e-04,  5.2597e-02, -2.1622e-01]],\n",
       "               \n",
       "                        [[ 7.8808e-02,  4.5606e-02, -5.1474e-03],\n",
       "                         [ 1.6320e-02, -7.2258e-02,  4.4972e-02],\n",
       "                         [ 1.6033e-02, -6.9873e-02,  4.5229e-02]],\n",
       "               \n",
       "                        [[ 5.2383e-02,  7.4248e-03,  8.0354e-02],\n",
       "                         [-6.5015e-02,  1.0633e-02,  5.2857e-03],\n",
       "                         [ 1.4724e-01, -5.7638e-02,  8.7776e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.2232e-01, -1.2476e-01,  3.7831e-02],\n",
       "                         [ 4.4739e-02, -5.0178e-02,  6.2006e-02],\n",
       "                         [ 1.8701e-02,  5.6971e-03, -1.4427e-02]],\n",
       "               \n",
       "                        [[ 8.3601e-02, -6.6391e-02,  1.3864e-02],\n",
       "                         [ 2.8174e-02, -8.7969e-03,  3.6312e-02],\n",
       "                         [-4.4223e-02,  1.1098e-01, -3.2832e-02]],\n",
       "               \n",
       "                        [[ 5.0170e-02, -9.6371e-03,  4.7216e-02],\n",
       "                         [ 6.2681e-02, -7.9320e-02, -3.3555e-02],\n",
       "                         [-6.5046e-02,  3.0743e-02,  9.3434e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.1696e-01,  9.2675e-02,  4.7110e-02],\n",
       "                         [ 1.4960e-02,  7.7798e-02,  6.5430e-02],\n",
       "                         [ 1.2184e-01, -4.4475e-02, -6.2099e-03]],\n",
       "               \n",
       "                        [[-1.1960e-02, -1.1295e-02, -4.0984e-02],\n",
       "                         [ 1.7604e-02, -2.9280e-02,  5.3968e-02],\n",
       "                         [ 7.6662e-05,  3.4200e-02,  1.5982e-02]],\n",
       "               \n",
       "                        [[ 3.7037e-02, -3.6217e-02, -1.6054e-02],\n",
       "                         [-7.7330e-02,  1.3780e-01,  4.2422e-02],\n",
       "                         [ 5.8128e-02,  4.2051e-03,  1.1773e-01]]]], device='cuda:0')),\n",
       "              ('conv2.bias',\n",
       "               tensor([ 0.0311, -0.0993,  0.0802, -0.0264, -0.0685, -0.0280, -0.0423,  0.0851,\n",
       "                        0.0739, -0.0083,  0.0614, -0.0916, -0.1088, -0.0796, -0.0303,  0.0563,\n",
       "                       -0.0961, -0.0185,  0.0712, -0.0244, -0.0538,  0.0340, -0.0362,  0.0186,\n",
       "                       -0.1260, -0.0671,  0.0569, -0.0590, -0.0113, -0.0908, -0.0120,  0.0466,\n",
       "                       -0.0803, -0.0328, -0.0651, -0.0121, -0.0094,  0.0264, -0.0618, -0.1172,\n",
       "                        0.0627, -0.0380, -0.0166, -0.0740,  0.0053, -0.0759, -0.0473, -0.0840,\n",
       "                        0.0272,  0.0360, -0.0554, -0.1091,  0.0399,  0.0463, -0.0669, -0.0019,\n",
       "                        0.0106, -0.0133,  0.0182, -0.0859,  0.0284,  0.0054, -0.0625,  0.0029],\n",
       "                      device='cuda:0')),\n",
       "              ('conv3.weight',\n",
       "               tensor([[[[ 9.9274e-02,  1.5295e-02,  3.0631e-02],\n",
       "                         [ 5.6966e-02,  1.2253e-01, -3.2131e-02],\n",
       "                         [-9.6694e-02,  3.0394e-02, -2.9457e-02]],\n",
       "               \n",
       "                        [[-2.9682e-02, -3.8424e-01,  5.3704e-02],\n",
       "                         [ 1.0722e-01, -8.4502e-02,  3.2357e-02],\n",
       "                         [ 1.0449e-01, -9.8891e-02,  1.1857e-01]],\n",
       "               \n",
       "                        [[-3.0040e-02, -2.8589e-02, -9.3151e-02],\n",
       "                         [-1.6796e-01, -1.4467e-01, -8.0951e-03],\n",
       "                         [ 1.0871e-02, -9.7913e-02,  1.0942e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.0842e-02,  3.5567e-02, -5.5538e-02],\n",
       "                         [-4.8390e-02,  2.9196e-03, -1.1935e-01],\n",
       "                         [-3.0420e-03,  2.8716e-02, -7.6250e-02]],\n",
       "               \n",
       "                        [[-1.5201e-03,  1.6293e-02, -1.9755e-01],\n",
       "                         [ 4.5078e-02, -9.3751e-02,  2.7655e-03],\n",
       "                         [ 1.4056e-01, -3.4308e-02,  2.0027e-02]],\n",
       "               \n",
       "                        [[ 1.5540e-02, -7.7099e-02, -9.2113e-02],\n",
       "                         [ 3.7720e-02,  6.5092e-02, -2.1036e-02],\n",
       "                         [-3.3031e-02, -5.8900e-02, -3.3539e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0652e-01,  1.1483e-01, -7.7564e-02],\n",
       "                         [ 3.1070e-02,  1.3348e-02, -2.0882e-01],\n",
       "                         [-2.3783e-02, -7.3080e-02, -7.1630e-02]],\n",
       "               \n",
       "                        [[ 5.0315e-02, -3.7645e-02, -3.6014e-02],\n",
       "                         [ 5.0444e-02, -8.5401e-02, -1.2956e-01],\n",
       "                         [ 1.9101e-01,  4.7654e-02, -1.6855e-01]],\n",
       "               \n",
       "                        [[-8.7629e-02,  7.2847e-03,  6.1025e-02],\n",
       "                         [ 1.0575e-01,  4.8642e-02, -1.0116e-02],\n",
       "                         [ 5.3700e-02,  1.2060e-01, -3.9779e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.4701e-01,  5.8170e-02, -8.4638e-02],\n",
       "                         [-6.7331e-02, -5.9553e-02, -1.8603e-01],\n",
       "                         [-1.0055e-02, -5.1790e-02, -1.5939e-01]],\n",
       "               \n",
       "                        [[-6.4629e-02, -6.5457e-02,  1.3596e-01],\n",
       "                         [-3.2314e-02,  3.8271e-02, -5.6828e-02],\n",
       "                         [-1.0641e-01,  9.5239e-03, -1.6550e-01]],\n",
       "               \n",
       "                        [[-1.5811e-02, -5.7016e-03, -4.1710e-02],\n",
       "                         [-2.7717e-02, -9.9132e-02, -2.0259e-01],\n",
       "                         [ 4.8544e-03, -1.5519e-01,  2.8706e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7133e-02, -3.4409e-02, -5.3102e-02],\n",
       "                         [-1.0613e-01,  1.0471e-01, -1.2692e-01],\n",
       "                         [-1.2626e-01, -1.6410e-02, -1.3648e-02]],\n",
       "               \n",
       "                        [[ 6.5148e-02,  6.5373e-02,  3.3360e-02],\n",
       "                         [ 5.4563e-02, -1.0141e-01,  1.7662e-02],\n",
       "                         [ 1.2926e-01, -1.2082e-01, -2.0570e-02]],\n",
       "               \n",
       "                        [[-1.2186e-02, -1.0720e-02, -1.7239e-02],\n",
       "                         [-4.2316e-02,  9.9075e-02,  1.6617e-03],\n",
       "                         [ 1.3469e-01, -7.0137e-02, -1.3717e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.9453e-01,  5.0897e-02, -6.1399e-02],\n",
       "                         [-3.0621e-02,  1.4309e-01, -8.3452e-02],\n",
       "                         [ 1.4597e-01,  4.8165e-02,  5.1344e-02]],\n",
       "               \n",
       "                        [[ 8.4756e-03,  6.1881e-02,  1.3659e-02],\n",
       "                         [-1.7148e-01,  6.3179e-02, -1.3437e-01],\n",
       "                         [-1.8882e-01, -7.6532e-03,  7.8164e-02]],\n",
       "               \n",
       "                        [[ 6.5278e-02, -4.3617e-02, -1.2482e-02],\n",
       "                         [-7.6404e-03, -6.2798e-03, -5.2594e-02],\n",
       "                         [-4.4536e-02,  2.4519e-02,  6.3524e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2291e-02,  4.8626e-02, -7.4062e-03],\n",
       "                         [-1.2673e-01,  6.3759e-02,  1.4512e-02],\n",
       "                         [-9.7063e-02, -1.9249e-02,  1.8892e-02]],\n",
       "               \n",
       "                        [[ 1.9619e-03,  1.3017e-01, -6.8437e-02],\n",
       "                         [-4.2145e-02, -1.0418e-01, -1.5012e-01],\n",
       "                         [ 5.6954e-02, -1.6508e-01, -1.3552e-01]],\n",
       "               \n",
       "                        [[-3.9958e-02, -6.4026e-02, -1.7097e-02],\n",
       "                         [ 1.6962e-02, -7.4196e-02, -1.1634e-01],\n",
       "                         [ 1.2515e-01, -9.0849e-02, -1.5216e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.3189e-02,  6.9842e-02, -8.8013e-02],\n",
       "                         [ 2.9896e-02,  8.5385e-02,  3.0668e-02],\n",
       "                         [ 8.6541e-02,  4.8970e-02, -2.6886e-02]],\n",
       "               \n",
       "                        [[ 7.4876e-03, -2.0115e-02, -1.1975e-01],\n",
       "                         [ 1.2554e-01,  1.2284e-01, -1.0468e-01],\n",
       "                         [ 2.9804e-03,  5.6214e-02,  1.6621e-01]],\n",
       "               \n",
       "                        [[-4.8837e-02,  2.9278e-02,  4.5865e-02],\n",
       "                         [-4.4594e-02,  3.3062e-02,  3.2814e-02],\n",
       "                         [-6.2437e-02, -1.7067e-02, -3.8017e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.2786e-02,  2.0091e-01, -1.2006e-02],\n",
       "                         [-7.1762e-02,  1.2028e-01,  1.3457e-01],\n",
       "                         [ 4.1671e-02, -8.2595e-02,  7.1179e-02]],\n",
       "               \n",
       "                        [[ 2.7694e-02, -8.4303e-02,  1.1298e-01],\n",
       "                         [ 5.6811e-03,  9.1122e-03,  1.5197e-01],\n",
       "                         [ 8.2004e-03, -2.4263e-02,  6.8290e-02]],\n",
       "               \n",
       "                        [[ 5.6965e-02, -7.7279e-02, -1.4411e-01],\n",
       "                         [-1.0158e-01,  1.7144e-03, -1.9119e-01],\n",
       "                         [-3.7246e-02, -3.8477e-02, -1.3245e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.5890e-02, -1.5415e-01,  5.1138e-02],\n",
       "                         [ 2.9054e-03, -9.4533e-03,  2.9842e-02],\n",
       "                         [ 1.6547e-02,  2.8875e-02, -1.0196e-01]],\n",
       "               \n",
       "                        [[-1.0056e-01, -5.8437e-02, -5.0725e-02],\n",
       "                         [ 8.6278e-02, -1.2874e-02,  5.4310e-02],\n",
       "                         [ 1.0410e-01,  2.2945e-01, -1.0810e-01]],\n",
       "               \n",
       "                        [[ 2.1221e-02, -4.3765e-02, -2.4501e-02],\n",
       "                         [ 2.9330e-02,  8.9087e-02,  1.1302e-02],\n",
       "                         [-1.4344e-01, -7.7108e-02,  5.4295e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0929e-01, -7.4972e-02,  7.0060e-02],\n",
       "                         [ 1.3070e-02, -6.5607e-02, -3.3153e-02],\n",
       "                         [-5.4712e-02,  5.6340e-02,  2.9055e-02]],\n",
       "               \n",
       "                        [[-1.6678e-01, -8.9886e-02, -3.0270e-04],\n",
       "                         [-1.2569e-01,  9.5974e-02, -8.7726e-02],\n",
       "                         [ 1.4214e-01,  3.3877e-02,  9.3904e-03]],\n",
       "               \n",
       "                        [[ 5.7291e-02,  6.3691e-02, -1.2375e-01],\n",
       "                         [-3.5228e-02,  4.0505e-02, -6.6134e-02],\n",
       "                         [-9.9578e-02, -4.8811e-03,  6.0820e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.9311e-02, -1.8976e-01, -1.0653e-01],\n",
       "                         [-1.0902e-01, -1.3179e-01, -5.2635e-02],\n",
       "                         [ 9.3217e-02, -1.6631e-01,  6.8378e-02]],\n",
       "               \n",
       "                        [[ 2.8126e-02, -8.8271e-03, -5.9088e-03],\n",
       "                         [-5.9879e-02,  4.7183e-03,  3.2696e-03],\n",
       "                         [ 4.1163e-02, -3.1181e-02, -3.7680e-02]],\n",
       "               \n",
       "                        [[ 1.0157e-02, -3.8142e-03, -2.8922e-02],\n",
       "                         [ 1.0804e-02, -7.5012e-02, -1.2805e-02],\n",
       "                         [ 5.8247e-02,  2.8371e-02,  9.1553e-02]]]], device='cuda:0')),\n",
       "              ('conv3.bias',\n",
       "               tensor([ 6.3784e-02,  3.9383e-02,  1.4493e-01,  2.2549e-02,  9.0123e-02,\n",
       "                        1.9451e-02,  5.6874e-02,  1.8076e-01, -6.1420e-02, -2.2003e-02,\n",
       "                        5.0433e-02,  1.4106e-01, -2.6235e-02,  1.4853e-01,  1.4055e-01,\n",
       "                        8.1953e-02,  1.5161e-01, -3.5576e-02,  1.0357e-01,  8.8448e-03,\n",
       "                        1.1797e-01,  1.0938e-01,  5.9317e-02, -8.2762e-02,  8.1547e-02,\n",
       "                        3.0643e-02,  3.8199e-02,  1.5326e-01,  7.6815e-02,  1.9034e-01,\n",
       "                        1.0317e-01,  8.9356e-02,  8.4024e-02, -5.2104e-02,  3.7465e-02,\n",
       "                        4.5356e-02,  6.2672e-02,  1.7929e-02,  4.6653e-02,  1.6817e-02,\n",
       "                        3.1921e-02,  1.0167e-01, -3.4200e-03,  1.5625e-02,  1.1241e-01,\n",
       "                        1.1978e-01,  1.1134e-01,  1.4907e-01,  1.1755e-01, -1.1835e-02,\n",
       "                        1.7009e-02,  4.6982e-02,  3.4166e-02, -6.6462e-02,  1.8225e-01,\n",
       "                        5.3015e-02,  5.9170e-02, -3.3768e-02,  5.8630e-02,  7.0676e-02,\n",
       "                        7.7013e-02,  1.4553e-01, -1.2716e-04,  1.3015e-02], device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[ 0.0694,  0.0336, -0.1075,  ..., -0.0314,  0.0731,  0.0063],\n",
       "                       [ 0.0669,  0.0593,  0.0094,  ...,  0.0066, -0.0761,  0.0048],\n",
       "                       [ 0.1227,  0.0306, -0.0428,  ...,  0.0106,  0.0680,  0.0352],\n",
       "                       ...,\n",
       "                       [ 0.1182,  0.0433, -0.0529,  ..., -0.0119,  0.0257,  0.0295],\n",
       "                       [ 0.0843,  0.0660,  0.0041,  ..., -0.0115,  0.0019,  0.0936],\n",
       "                       [ 0.0254,  0.0025, -0.0333,  ..., -0.0229, -0.0376, -0.0315]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.0886,  0.1993,  0.1330,  0.0631,  0.0957, -0.0060, -0.0477,  0.0718,\n",
       "                        0.2288, -0.0074, -0.0089,  0.2189, -0.0230, -0.0148,  0.2201, -0.0350,\n",
       "                        0.0748,  0.0033,  0.1971, -0.0060,  0.1996, -0.0095, -0.0327,  0.2164,\n",
       "                        0.0755, -0.0263, -0.0059,  0.2190,  0.2272,  0.0966,  0.2445,  0.2331,\n",
       "                        0.2097,  0.2006,  0.2341,  0.0818,  0.2203,  0.1898,  0.0836, -0.0063,\n",
       "                       -0.0245,  0.2078,  0.0710,  0.2084, -0.0060, -0.0317,  0.1731, -0.0301,\n",
       "                        0.2037,  0.2136, -0.0122, -0.0060, -0.0060,  0.0786,  0.2201,  0.0881,\n",
       "                       -0.0077,  0.2166, -0.0340, -0.0071,  0.0687,  0.2363,  0.1842, -0.0098],\n",
       "                      device='cuda:0')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[-0.4357,  0.2037, -0.2929,  ...,  0.1531,  0.0567, -0.1604],\n",
       "                       [ 0.0725, -0.0780,  0.1895,  ..., -0.1041, -0.0829,  0.1617],\n",
       "                       [-0.0014, -0.0605, -0.0421,  ..., -0.0790, -0.1039,  0.1741],\n",
       "                       ...,\n",
       "                       [-0.2060,  0.1943,  0.1575,  ...,  0.1716, -0.0919,  0.1964],\n",
       "                       [ 0.0645, -0.0571, -0.0687,  ..., -0.1199, -0.0667,  0.1708],\n",
       "                       [-0.1805,  0.2585, -0.0705,  ..., -0.1532, -0.1132, -0.0048]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc2.bias',\n",
       "               tensor([ 1.5410, -0.2611, -0.2319, -0.2436, -0.0729, -0.0711, -0.2513, -0.0223,\n",
       "                       -0.1056, -0.1646, -0.1086, -0.1194, -0.1741, -0.1731, -0.1457, -0.6083,\n",
       "                       -0.0898, -0.1368, -0.1829, -0.2864, -0.0719, -0.0547, -0.2348, -0.1135,\n",
       "                       -0.1486,  0.0838, -0.0885, -0.2279, -0.3482, -0.0701, -0.0079, -0.1235,\n",
       "                       -0.2092, -0.2340,  0.0361, -0.1825,  0.0936,  0.0139, -0.1392, -0.1052,\n",
       "                       -0.0595, -0.0500, -0.0384, -0.2032, -0.3194, -0.1207, -0.1698, -0.1284,\n",
       "                       -0.3497, -0.1500, -0.0043], device='cuda:0'))]),\n",
       " 'model_config': {'input_shape': (50, 28),\n",
       "  'n_classes': 51,\n",
       "  'dropout': 0.3,\n",
       "  'flatten_size': 5376},\n",
       " 'label_encoder': LabelEncoder(),\n",
       " 'dataset_info': {'n_samples': 9610,\n",
       "  'sequence_length': 50,\n",
       "  'n_features': 28,\n",
       "  'n_classes': 51,\n",
       "  'class_names': ['nothing',\n",
       "   'กาแฟ',\n",
       "   'กิน',\n",
       "   'ขอบคุณ',\n",
       "   'คำถาม',\n",
       "   'คุณ',\n",
       "   'ฉัน',\n",
       "   'ชอบ',\n",
       "   'ช่วย',\n",
       "   'ดี',\n",
       "   'ดื่ม',\n",
       "   'ตอนนี้',\n",
       "   'ต้องการ',\n",
       "   'ทำ',\n",
       "   'ทำงาน',\n",
       "   'ทีหลัง',\n",
       "   'ที่นั่น',\n",
       "   'ที่นี่',\n",
       "   'นอน',\n",
       "   'น้ำ',\n",
       "   'บ้าน',\n",
       "   'ป่วย',\n",
       "   'พรุ่งนี้',\n",
       "   'พูด',\n",
       "   'มา',\n",
       "   'มี',\n",
       "   'รถ',\n",
       "   'รอ',\n",
       "   'ร้อน',\n",
       "   'ร้าย',\n",
       "   'วันนี้',\n",
       "   'วิ่ง',\n",
       "   'หนังสือ',\n",
       "   'หนาว',\n",
       "   'อันตราย',\n",
       "   'อาหาร',\n",
       "   'อ่าน',\n",
       "   'เขียน',\n",
       "   'เข้าใจ',\n",
       "   'เดิน',\n",
       "   'เพื่อน',\n",
       "   'เมื่อวาน',\n",
       "   'เรา',\n",
       "   'เรียน',\n",
       "   'เล็ก',\n",
       "   'เล่น',\n",
       "   'เวลา',\n",
       "   'โทรศัพท์',\n",
       "   'โรงเรียน',\n",
       "   'ใหญ่',\n",
       "   'ไป'],\n",
       "  'input_shape': (50, 28)},\n",
       " 'training_info': {'scheduler_used': 'warmup_cosine',\n",
       "  'final_train_acc': 99.66181061394381,\n",
       "  'final_val_acc': 98.85535900104058,\n",
       "  'final_train_loss': 0.8237826430107936,\n",
       "  'final_val_loss': 0.7728117012208507,\n",
       "  'total_epochs': 52},\n",
       " 'training_history': {'train_loss': [2.142144301706109,\n",
       "   1.7191099253567783,\n",
       "   1.59530424677636,\n",
       "   1.4880989809666783,\n",
       "   1.3820051462197107,\n",
       "   1.2758695823101958,\n",
       "   1.2110153377548722,\n",
       "   1.1471479687808959,\n",
       "   1.0997539177413815,\n",
       "   1.059334660857177,\n",
       "   1.0320046332256854,\n",
       "   1.0128419241629356,\n",
       "   0.9848138217098457,\n",
       "   0.9655116801419534,\n",
       "   0.9497858995248464,\n",
       "   0.9376647171895366,\n",
       "   0.9201100286373423,\n",
       "   0.9213441033993871,\n",
       "   0.9128173496112351,\n",
       "   0.8988648288506121,\n",
       "   0.8909337023072992,\n",
       "   0.8852547993344709,\n",
       "   0.8779926694129124,\n",
       "   0.8750826731201046,\n",
       "   0.8686704330207887,\n",
       "   0.8638416962190107,\n",
       "   0.8701566112928154,\n",
       "   0.8614781607281078,\n",
       "   0.8607923176662982,\n",
       "   0.8580401515172533,\n",
       "   0.8527581332143673,\n",
       "   0.8509966095616995,\n",
       "   0.8436447662755477,\n",
       "   0.8403160897168246,\n",
       "   0.8384011949389434,\n",
       "   0.8415682503014557,\n",
       "   0.839426558372403,\n",
       "   0.835964089090174,\n",
       "   0.836951897656622,\n",
       "   0.8314776627485417,\n",
       "   0.8344127718082144,\n",
       "   0.831232205895353,\n",
       "   0.8269691743141363,\n",
       "   0.8297809638267706,\n",
       "   0.8261070241612837,\n",
       "   0.8224340894005515,\n",
       "   0.8221951713246748,\n",
       "   0.8210053621244825,\n",
       "   0.8151406951187071,\n",
       "   0.818980300229443,\n",
       "   0.8145283642879202,\n",
       "   0.8237826430107936],\n",
       "  'train_acc': [57.92143600416233,\n",
       "   67.93704474505724,\n",
       "   71.96930280957336,\n",
       "   76.61290322580645,\n",
       "   80.48907388137357,\n",
       "   85.2627471383975,\n",
       "   87.52601456815817,\n",
       "   89.9063475546306,\n",
       "   91.85744016649323,\n",
       "   93.70447450572321,\n",
       "   94.39386056191468,\n",
       "   95.25234131113423,\n",
       "   96.50104058272633,\n",
       "   96.70915712799167,\n",
       "   97.24245577523413,\n",
       "   97.67169614984391,\n",
       "   97.94484911550468,\n",
       "   98.11394380853278,\n",
       "   98.28303850156088,\n",
       "   98.55619146722164,\n",
       "   98.8423517169615,\n",
       "   98.72528616024974,\n",
       "   98.89438085327784,\n",
       "   99.18054110301769,\n",
       "   99.12851196670135,\n",
       "   99.12851196670135,\n",
       "   99.06347554630594,\n",
       "   99.24557752341312,\n",
       "   99.0894901144641,\n",
       "   99.21956295525494,\n",
       "   99.27159209157128,\n",
       "   99.29760665972945,\n",
       "   99.49271592091571,\n",
       "   99.66181061394381,\n",
       "   99.4146722164412,\n",
       "   99.5837669094693,\n",
       "   99.45369406867846,\n",
       "   99.51873048907387,\n",
       "   99.53173777315297,\n",
       "   99.55775234131113,\n",
       "   99.51873048907387,\n",
       "   99.57075962539022,\n",
       "   99.55775234131113,\n",
       "   99.55775234131113,\n",
       "   99.66181061394381,\n",
       "   99.68782518210197,\n",
       "   99.70083246618105,\n",
       "   99.64880332986472,\n",
       "   99.76586888657648,\n",
       "   99.73985431841831,\n",
       "   99.73985431841831,\n",
       "   99.66181061394381],\n",
       "  'val_loss': [1.5408507277888637,\n",
       "   1.5488038947505336,\n",
       "   1.3395117540513315,\n",
       "   1.224256573184844,\n",
       "   1.1095875443950776,\n",
       "   1.0178791207651938,\n",
       "   0.9721326501138748,\n",
       "   0.9371541969237789,\n",
       "   0.9049810863310291,\n",
       "   0.8811823744927684,\n",
       "   0.8566516080210286,\n",
       "   0.8562300993550208,\n",
       "   0.8404845633814412,\n",
       "   0.8334595849437099,\n",
       "   0.8148130582224938,\n",
       "   0.8173931779399994,\n",
       "   0.8105601918312811,\n",
       "   0.8229230949955602,\n",
       "   0.8245238584856833,\n",
       "   0.8028966226885396,\n",
       "   0.7979120150689156,\n",
       "   0.7996094880565521,\n",
       "   0.7948733952737623,\n",
       "   0.7929424951153417,\n",
       "   0.8063215498001345,\n",
       "   0.7937448793841947,\n",
       "   0.798700790251455,\n",
       "   0.7898199500576142,\n",
       "   0.7854060530662537,\n",
       "   0.782489913125192,\n",
       "   0.7819387624340672,\n",
       "   0.7782317822979342,\n",
       "   0.7831627053599204,\n",
       "   0.7798003054434254,\n",
       "   0.782497065682565,\n",
       "   0.7802450906845831,\n",
       "   0.7780955356936301,\n",
       "   0.7802904978875191,\n",
       "   0.7780754393146884,\n",
       "   0.7763347068140584,\n",
       "   0.7743102254406098,\n",
       "   0.7785865299163326,\n",
       "   0.7728975453684407,\n",
       "   0.7811345631076444,\n",
       "   0.7798024877425163,\n",
       "   0.7726188917313853,\n",
       "   0.7761307320287151,\n",
       "   0.7723617534483632,\n",
       "   0.7732602165591332,\n",
       "   0.7758102724629063,\n",
       "   0.7765122402098871,\n",
       "   0.7728117012208507],\n",
       "  'val_acc': [75.28616024973985,\n",
       "   74.86992715920915,\n",
       "   83.45473465140479,\n",
       "   87.2528616024974,\n",
       "   91.20707596253902,\n",
       "   93.60041623309053,\n",
       "   94.17273673257024,\n",
       "   95.525494276795,\n",
       "   96.67013527575442,\n",
       "   96.7741935483871,\n",
       "   97.24245577523413,\n",
       "   97.81477627471384,\n",
       "   97.86680541103017,\n",
       "   97.97086368366286,\n",
       "   98.43912591050989,\n",
       "   98.28303850156088,\n",
       "   97.91883454734652,\n",
       "   98.69927159209158,\n",
       "   98.28303850156088,\n",
       "   98.59521331945889,\n",
       "   98.49115504682622,\n",
       "   98.59521331945889,\n",
       "   98.43912591050989,\n",
       "   98.43912591050989,\n",
       "   98.69927159209158,\n",
       "   98.59521331945889,\n",
       "   98.54318418314256,\n",
       "   98.64724245577523,\n",
       "   98.54318418314256,\n",
       "   98.75130072840791,\n",
       "   98.75130072840791,\n",
       "   99.11550468262227,\n",
       "   98.75130072840791,\n",
       "   99.01144640998959,\n",
       "   98.59521331945889,\n",
       "   98.54318418314256,\n",
       "   99.01144640998959,\n",
       "   98.85535900104058,\n",
       "   98.95941727367325,\n",
       "   98.90738813735692,\n",
       "   98.95941727367325,\n",
       "   98.80332986472425,\n",
       "   99.01144640998959,\n",
       "   98.64724245577523,\n",
       "   98.69927159209158,\n",
       "   98.95941727367325,\n",
       "   99.06347554630594,\n",
       "   99.06347554630594,\n",
       "   98.85535900104058,\n",
       "   98.85535900104058,\n",
       "   99.11550468262227,\n",
       "   98.85535900104058],\n",
       "  'val_f1': [72.9012725430585,\n",
       "   72.38189498233648,\n",
       "   81.86897853664355,\n",
       "   86.55137238726344,\n",
       "   90.91155768586644,\n",
       "   93.51463486133099,\n",
       "   93.9274315743807,\n",
       "   95.5475678340381,\n",
       "   96.67134111996708,\n",
       "   96.77269142170923,\n",
       "   97.24005682331526,\n",
       "   97.83136060093352,\n",
       "   97.86937352388217,\n",
       "   97.94579503581433,\n",
       "   98.44524638383953,\n",
       "   98.28477841424058,\n",
       "   97.91318150703367,\n",
       "   98.69592963850764,\n",
       "   98.31214375409114,\n",
       "   98.60977660593969,\n",
       "   98.51161668547897,\n",
       "   98.59219719524712,\n",
       "   98.47047931599687,\n",
       "   98.46982952789568,\n",
       "   98.70481840347462,\n",
       "   98.61576097018994,\n",
       "   98.5649541935937,\n",
       "   98.66316746485683,\n",
       "   98.5618680786583,\n",
       "   98.75349911938952,\n",
       "   98.75909401094356,\n",
       "   99.11270742691563,\n",
       "   98.76220685147193,\n",
       "   99.0125573447338,\n",
       "   98.62091587662069,\n",
       "   98.55735612379142,\n",
       "   99.0205029539365,\n",
       "   98.85254312316971,\n",
       "   98.95433963602702,\n",
       "   98.90988535836944,\n",
       "   98.96041572285272,\n",
       "   98.80949204012256,\n",
       "   99.01722336600193,\n",
       "   98.64450436236568,\n",
       "   98.71767684908338,\n",
       "   98.96351695737091,\n",
       "   99.06759271638965,\n",
       "   99.06502236972275,\n",
       "   98.85736491015687,\n",
       "   98.86044591311959,\n",
       "   99.1185792558019,\n",
       "   98.86594437927295],\n",
       "  'learning_rates': [0.001,\n",
       "   0.0,\n",
       "   0.0001,\n",
       "   0.0002,\n",
       "   0.0003,\n",
       "   0.0004,\n",
       "   0.0005,\n",
       "   0.0006,\n",
       "   0.0007,\n",
       "   0.0008,\n",
       "   0.0009000000000000001,\n",
       "   0.001,\n",
       "   0.0009996957180960385,\n",
       "   0.0009987832431047822,\n",
       "   0.0009972636867364526,\n",
       "   0.0009951389003364144,\n",
       "   0.000992411472629598,\n",
       "   0.000989084726566536,\n",
       "   0.00098516271527486,\n",
       "   0.0009806502171211904,\n",
       "   0.0009755527298894294,\n",
       "   0.0009698764640825614,\n",
       "   0.0009636283353561104,\n",
       "   0.0009568159560924792,\n",
       "   0.0009494476261264341,\n",
       "   0.0009415323226330341,\n",
       "   0.0009330796891903273,\n",
       "   0.0009241000240301348,\n",
       "   0.0009146042674912434,\n",
       "   0.0009046039886902864,\n",
       "   0.0008941113714265576,\n",
       "   0.0008831391993379295,\n",
       "   0.0008717008403259585,\n",
       "   0.0008598102302691563,\n",
       "   0.0008474818560442692,\n",
       "   0.0008347307378762498,\n",
       "   0.0008215724110384265,\n",
       "   0.0008080229069251664,\n",
       "   0.0007940987335200904,\n",
       "   0.0007798168552836381,\n",
       "   0.0007651946724844859,\n",
       "   0.0007502500000000002,\n",
       "   0.0007350010456115525,\n",
       "   0.0007194663878211442,\n",
       "   0.0007036649532163624,\n",
       "   0.0006876159934112483,\n",
       "   0.0006713390615911717,\n",
       "   0.0006548539886902864,\n",
       "   0.0006381808592305911,\n",
       "   0.0006213399868520341,\n",
       "   0.0006043518895634708,\n",
       "   0.0005872372647446319]},\n",
       " 'save_timestamp': '2025-08-03T12:00:29.772942',\n",
       " 'pytorch_version': '2.7.1+cu128'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "560b8042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "tensor(21, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from scipy import signal\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# os.environ[\"MP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "class CNNTimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, input_shape, n_classes, dropout=0.3):\n",
    "        \"\"\"\n",
    "        CNN-based Time Series Classifier following your architecture diagram\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Tuple (sequence_length, n_features) - e.g., (121, 21)\n",
    "            n_classes: Number of output classes\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(CNNTimeSeriesClassifier, self).__init__()\n",
    "        \n",
    "        seq_len, n_features = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_rate = dropout\n",
    "        \n",
    "        # Input normalization layer\n",
    "        self.normalization = nn.BatchNorm1d(n_features)\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch, channels, height, width)\n",
    "        # We'll treat sequence as height and features as width, with 1 channel\n",
    "        # Input shape: (None, 1, seq_len, n_features) - e.g., (None, 1, 121, 21)\n",
    "        # First Conv2D block\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, \n",
    "            out_channels=32, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after first conv+pool\n",
    "        # After conv1: (None, 32, 121, 21) -> (None, 32, 119, 19) with padding=1\n",
    "        # After pool1: (None, 32, 119, 19) -> (None, 32, 59, 9)\n",
    "        h1, w1 = seq_len // 2, n_features // 2\n",
    "        \n",
    "        # Second Conv2D block\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Calculate shape after second conv+pool\n",
    "        # After conv2: (None, 64, 59, 9) -> (None, 64, 57, 7) with padding=1\n",
    "        # After pool2: (None, 64, 57, 7) -> (None, 64, 28, 3)\n",
    "        h2, w2 = h1 // 2, w1 // 2\n",
    "        \n",
    "        # Third Conv2D block\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        # Calculate final conv output shape\n",
    "        # After conv3: (None, 64, 28, 3) -> (None, 64, 26, 1) with padding=1\n",
    "        h3, w3 = h2, w2\n",
    "        \n",
    "        # Calculate flattened size dynamically\n",
    "        self.flatten_size = 64 * h3 * w3\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 64)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "        # Activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights properly\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, n_features)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Normalize along feature dimension\n",
    "        # Reshape for BatchNorm1d: (batch_size * seq_len, n_features)\n",
    "        x_norm = x.view(-1, x.size(2))\n",
    "        # print(x_norm)\n",
    "        # ([print(i.dtype) for i in x_norm])\n",
    "        x_norm = self.normalization(x_norm)\n",
    "        x = x_norm.view(batch_size, x.size(1), x.size(2))\n",
    "        \n",
    "        # Reshape for 2D convolution: (batch_size, 1, seq_len, n_features)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # First Conv2D + MaxPool2D\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second Conv2D + MaxPool2D\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Third Conv2D\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # First Dense layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Dense layer (output)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return model configuration for saving\"\"\"\n",
    "        return {\n",
    "            'input_shape': self.input_shape,\n",
    "            'n_classes': self.n_classes,\n",
    "            'dropout': self.dropout_rate,\n",
    "            'flatten_size': self.flatten_size\n",
    "        }\n",
    "# dicta = torch.load(r\"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\cnn_timeseries_model_20250803_120029.pth\",weights_only=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_data(features):\n",
    "    chunk_size = 50\n",
    "    # features = torch.rand(30,28)\n",
    "    # sequences = []\n",
    "    if len(features) >= 50:\n",
    "        # If longer than chunk_size, use uniform sampling\n",
    "        indices = np.linspace(0, len(features)-1, chunk_size, dtype=int)\n",
    "        sequence = features[indices]\n",
    "    else:\n",
    "        # If shorter, pad with zeros at the end\n",
    "        sequence = np.zeros((chunk_size, features.shape[1]))\n",
    "        sequence[:len(features)] = features\n",
    "\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.from_numpy(sequence).to(\"cuda\")\n",
    "    else:\n",
    "        return torch.from_numpy(sequence)\n",
    "    \n",
    "\n",
    "model_path = \"F:\\Hybridmodel-project\\Sign_Language_Detection\\model\\model_96.pt\"\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.load(rf\"{model_path}\",weights_only=False)\n",
    "    \n",
    "    model.to(\"cuda\")\n",
    "else:\n",
    "    model = torch.load(rf\"{model_path}\",weights_only=False,map_location=torch.device('cpu'))\n",
    "    \n",
    "    # model\n",
    "model.double()\n",
    "model.eval()\n",
    "datas = torch.rand(1,28).double()\n",
    "\n",
    "data = torch.rand(1,28).double()\n",
    "i = 0\n",
    "while i<20:\n",
    "\n",
    "    datas = torch.concat([datas,data])\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "print(datas.dtype)\n",
    "tas = convert_data(datas)\n",
    "# print(\"ashj\",tas.dtype)\n",
    "answer = torch.argmax(model(tas.unsqueeze(0)))\n",
    "print(answer)\n",
    "# finalans = vocap[str(answer.item())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a72fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2792, 0.5052, 0.1211,  ..., 0.3130, 0.2965, 0.4513],\n",
       "        [0.8418, 0.7954, 0.3356,  ..., 0.8429, 0.9458, 0.6651],\n",
       "        [0.8418, 0.7954, 0.3356,  ..., 0.8429, 0.9458, 0.6651],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
