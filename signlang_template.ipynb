{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc2df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from scipy import signal\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "# os.environ[\"MP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e3103",
   "metadata": {},
   "source": [
    "## Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e539c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_linear(nn.Module):\n",
    "    def __init__(self,chunk =10,sigmoid_state=True,len_input = 16,outputa = 50):\n",
    "        super().__init__()\n",
    "        if chunk == 10:\n",
    "            sep = 384//4 # due to 2 maxPool1d Kernel_size = 2\n",
    "        if chunk == 50:\n",
    "            sep = 1280\n",
    "        if chunk == 100:\n",
    "            sep = 3200//4\n",
    "        if chunk == 200:\n",
    "            sep = 6400//4\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(chunk,128)\n",
    "        \n",
    "        self.biLSTM = nn.LSTM(chunk,128,bidirectional=True)\n",
    "        self.linear1 = nn.Linear(7168,128)\n",
    "        self.Lazyl1 = nn.LazyLinear(128)\n",
    "        self.linear2 = nn.Linear(128,outputa)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "        self.sigmoid_state = sigmoid_state\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1,(hn,cn) = self.biLSTM(x)\n",
    "        out1 = out1.flatten()\n",
    "        output = self.Lazyl1(out1)\n",
    "        y_final = self.linear2(output)\n",
    "        \n",
    "        if self.sigmoid_state:\n",
    "            y_final = self.sigmoid(y_final)\n",
    "        else:\n",
    "            y_final = self.softmax(y_final)\n",
    "\n",
    "        return y_final\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path,\n",
    "                 batch=16,\n",
    "                 chunk = 100,\n",
    "                 vocab_path = \"../Sign_Language_Detection/label.json\",\n",
    "                table:bool = False,\n",
    "                dataframe=None):\n",
    "        \n",
    "        \n",
    "        with open(vocab_path,\"r\") as f:\n",
    "            compare = json.load(f)\n",
    "        self.vocab = len(compare)\n",
    "        \n",
    "        if not table:\n",
    "            self._data_csv = pd.read_csv(csv_path)\n",
    "        else:\n",
    "            self._data_csv = dataframe\n",
    "        \n",
    "        \n",
    "        self._data_csv = self._data_csv[~(self._data_csv.Label.isin([ \"cooldown\",\"error_redo\",\"break_time\",]))]\n",
    "        self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n",
    "        self._data_csv = self._data_csv.drop(columns=[\"timestamp_ms\"])\n",
    "        self.train_data = self.convert_data_csv_train(self._data_csv,compare,segment=chunk,range_data=25)\n",
    "        # print(len(self.train_data))\n",
    "        \n",
    "        print(self.train_data.size())\n",
    "        fity = []\n",
    "        normal =[]\n",
    "        for i in self.train_data:\n",
    "            # print(i[:,-1][0])\n",
    "            if int(i[:,-1][-1]) == 0:\n",
    "                fity.append(i)\n",
    "            else:\n",
    "                normal.append(i)\n",
    "        # print(len(fity))\n",
    "        # print(len(normal))\n",
    "        fity = random.sample(fity,int(len(fity) * 0.5))\n",
    "        normal.extend(fity)\n",
    "        self.train_data = normal\n",
    "        self.nums  = len(self.train_data)\n",
    "        self.answer_transform = []\n",
    "    \n",
    "        self.train_data = torch.tensor([i.tolist() for i in self.train_data])\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(self.train_data)):\n",
    "            # print(self.train_data)\n",
    "            \n",
    "            \n",
    "            dummy = torch.zeros(self.vocab)\n",
    "            ct = Counter(self.train_data[i][:,-1].tolist()).most_common()\n",
    "            if len(ct) == 2 and ct[0][0] ==0:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[1]\n",
    "            else:\n",
    "                idx,count = Counter(self.train_data[i][:,-1].tolist()).most_common()[0]\n",
    "            \n",
    "            dummy[int(idx)] = 1\n",
    "            self.answer_transform.append(dummy)\n",
    "        \n",
    "        self.train_data = self.train_data[:,:,:-1]\n",
    "        self.nums,self.segment,self.input = self.train_data.size()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.train_data[index]\n",
    "        answer = self.answer_transform[index]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            return inputs.to(torch.float32).movedim(1,0).to(\"cuda\"),answer.to(\"cuda\")\n",
    "        else:\n",
    "            return inputs.to(torch.float32).movedim(1,0),answer\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def len_answer(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def data_info(self):\n",
    "        return self.nums,self.segment,self.input,self.train_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def convert_data_csv_train(self,data,compare,segment=50,range_data = 0):\n",
    "\n",
    "        datta = []\n",
    "        previous = None\n",
    "        samples = []\n",
    "        abc= []\n",
    "        \n",
    "        \n",
    "        data['group_id'] = (data['Label'] != data['Label'].shift()).cumsum()\n",
    "        grouped_dfs = [g.drop(columns='group_id').values for _, g in data.groupby('group_id')]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"len(data): \",len(grouped_dfs))\n",
    "        print(\"filter Value\")\n",
    "        all_data = []\n",
    "        for i in tqdm(grouped_dfs,total = len(grouped_dfs)):\n",
    "            if len(i) > range_data:\n",
    "                all_data.append(i)\n",
    "\n",
    "\n",
    "        print(\"pad&mean Value\")\n",
    "\n",
    "        real = []\n",
    "        for i in tqdm(all_data,total = len(all_data)):\n",
    "            segment = segment\n",
    "            if len(i) < segment:\n",
    "                tensor_df = (torch.tensor(i))\n",
    "                n,b = tensor_df.size()\n",
    "                padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, segment-n, 0), mode='constant', value=0)\n",
    "                # print(padded_tensor.size())\n",
    "                real.append(padded_tensor.tolist())\n",
    "            else:\n",
    "                step = int(np.ceil(len(i)//segment))\n",
    "                temp = []\n",
    "                for k in range(segment):\n",
    "                    temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "                real.append(temp)\n",
    "\n",
    "        train_data = torch.tensor(real)\n",
    "        return train_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49c8ab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7565c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481770\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "for i in glob.glob(r\"./collect_data/new_data/*\"):\n",
    "    df = pd.read_csv(rf\"{i}\")\n",
    "    base_df = pd.concat([base_df,df])\n",
    "print(len(base_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d137af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=50,table=True,dataframe=base_df)\n",
    "# data_answer = []\n",
    "# for inputs,answer in tqdm(train_dataset):\n",
    "      \n",
    "      # try:\n",
    "          # print(torch.tensor(inputs[i:i+chunk]).size())\n",
    "    #   data_answer.append(answer)\n",
    "\n",
    "\n",
    "# train.size()\n",
    "\n",
    "# with open(\"rollback.json\",'r') as f:\n",
    "#     ct = json.load(f)\n",
    "    \n",
    "    \n",
    "# print(len(data_answer))\n",
    "# label_list = [int(torch.argmax(i)) for i in data_answer] \n",
    "# nv = Counter(label_list)\n",
    "# print(nv.most_common())\n",
    "\n",
    "\n",
    "\n",
    "# not_eng = []\n",
    "# for i,v in nv.most_common():\n",
    "#     print(f\"{ct[str(i)]} : {v} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f223ea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\1706295445.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  6811\n",
      "filter Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fbf1a197e4407daef2c4726c04427e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dea6909dfd437aa7c5e61c2d56fc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3579, 50, 29])\n",
      " data train = 3490 with 28 feature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a08737e4674fbb941e13324207c505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1 loss = 0.019909195601940155 with lr = [2e-05]\n",
      "best loss at epoch = 1 with 0.019909195601940155\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch = 1\n",
    "lr = 2e-5\n",
    "chunk = 50\n",
    "e = 0\n",
    "best_loss = 0\n",
    "path_save = \"../Sign_Language_Detection/model/Version1\"\n",
    "num_still = 0\n",
    "sigoid_state = True\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = CustomDataset(\"collect_data/20250624_101902_ชาตชาย24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=50,table=True,dataframe=base_df)\n",
    "\n",
    "\n",
    "len_output = train_dataset.len_answer()\n",
    "len_input = train_dataset.data_info()[-2]\n",
    "train_dataset = DataLoader(train_dataset,batch_size=batch_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  lstm = lstm_linear(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output).to(\"cuda\")\n",
    "else:\n",
    "  lstm = lstm_linear(chunk,sigmoid_state=sigoid_state,len_input=len_input,outputa=len_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(),lr=lr,weight_decay=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',patience =3  ,min_lr = 5e-6,factor=0.5)\n",
    "print(f\" data train = {int(len(train_dataset)*batch_size)} with {len_input} feature\")\n",
    "\n",
    "\n",
    "n = 0\n",
    "for param in lstm.parameters():\n",
    "  param.requires_grad=True\n",
    "lstm.train()\n",
    "\n",
    "for k in range(1,epoch+1):\n",
    "    loss_total = 0\n",
    "    data_answer = []\n",
    "    for inputs,answer in tqdm(train_dataset):\n",
    "      answer = answer[0]\n",
    "      data_answer.append(answer)\n",
    "      output = lstm(inputs)\n",
    "      optimizer.zero_grad()\n",
    "      if torch.argmax(answer).item() == 0:\n",
    "        loss = criterion(output,answer)\n",
    "      else:\n",
    "        loss = criterion(output,answer)\n",
    "      \n",
    "      \n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_total += loss\n",
    "      n+=1\n",
    "        \n",
    "    if best_loss == 0 or best_loss > loss_total/len(train_dataset):\n",
    "      best_loss = loss_total/len(train_dataset)\n",
    "      state_dict = lstm.state_dict()\n",
    "      e = k\n",
    "      num_still = 0\n",
    "    else:\n",
    "      num_still +=1\n",
    "      \n",
    "    scheduler.step(loss_total/len(train_dataset))\n",
    "    num_still = 0\n",
    "    if num_still >= 3:\n",
    "      print(\"step up to learning = \",scheduler.get_last_lr())\n",
    "      break\n",
    "      \n",
    "    \n",
    "    print(f\"epoch number {k} loss = {loss_total/len(train_dataset)} with lr = {scheduler.get_last_lr()}\")\n",
    "print(f\"best loss at epoch = {e} with {best_loss}\")\n",
    "torch.save(state_dict,f\"{path_save}/model_epoch_{e}\")\n",
    "torch.save(lstm, r\"./model/Version1/finalmodel.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9559fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data):  201\n",
      "filter Value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wayupuk sommuang\\AppData\\Local\\Temp\\ipykernel_22228\\1706295445.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data_csv[\"Label\"] = self._data_csv[\"Label\"].apply(lambda x:compare[x])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62c30a1e24d4882af47d674e8ac4dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad&mean Value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b043551e315049d8a6efc1e9836de552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 50, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f77cad8fed4764a2a79f83b3bbd88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(rf\"F:\\Hybridmodel-project\\Sign_Language_Detection\\collect_data\\20250715_111750_DATA_INDICATOR_sensor.csv\")\n",
    "# test_df  = test_df[test_df.columns[1:]]\n",
    "test_dataset = CustomDataset(\"collect_data/20250624_131408_พชชาภา24062025_sensor.csv\",vocab_path=\"../Sign_Language_Detection/label.json\",chunk=chunk,table=True,dataframe=test_df)\n",
    "test_dataset = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,answer in tqdm(test_dataset):\n",
    "        output = lstm(inputs)\n",
    "        y_pred += [(torch.argmax(output,dim=0)).tolist()]\n",
    "        y_true += (torch.argmax(answer,dim=1)).tolist()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9202f260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score     0.10091743119266056\n",
      "recal score  0.10091743119266056\n",
      "acc score    0.10091743119266056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,accuracy_score\n",
    "f1_scores = f1_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"f1 score    \",f1_scores)\n",
    "recall_scores = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(\"recal score \",recall_scores)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"acc score   \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6ef8d",
   "metadata": {},
   "source": [
    "# How to use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b5a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_csv_train(data,segment=50):\n",
    "\n",
    "    real = []\n",
    "    for i in tqdm(data,total = len(data)):\n",
    "        segment = segment\n",
    "        if len(i) < segment:\n",
    "            # tensor_df = (torch.tensor(i.clone()))\n",
    "            tensor_df = i.clone()\n",
    "            n,b = tensor_df.size()\n",
    "            padded_tensor = torch.nn.functional.pad(tensor_df, pad=(0, 0, segment-n, 0), mode='constant', value=0)\n",
    "            # print(padded_tensor.size())\n",
    "            real.append(padded_tensor.tolist())\n",
    "        else:\n",
    "            step = int(np.ceil(len(i)//segment))\n",
    "            temp = []\n",
    "            for k in range(segment):\n",
    "                temp.append(torch.mean(torch.tensor(i[k*step:(k+1)*step]),dim=0).tolist())\n",
    "            real.append(temp)\n",
    "    return torch.tensor(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c441d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r\"./model/Version1/finalmodel.pt\",weights_only=False)\n",
    "with open(r\"rollback.json\",'r') as f:\n",
    "    vocap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aad08ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11982\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.DataFrame()\n",
    "for i in glob.glob(r\"./collect_data/new_data/*\"):\n",
    "    df = pd.read_csv(rf\"{i}\")\n",
    "    base_df = pd.concat([base_df,df])\n",
    "    break\n",
    "print(len(base_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fad0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>ax_slav</th>\n",
       "      <th>ay_slav</th>\n",
       "      <th>az_slav</th>\n",
       "      <th>gx_slav</th>\n",
       "      <th>gy_slav</th>\n",
       "      <th>gz_slav</th>\n",
       "      <th>angle_x_slav</th>\n",
       "      <th>angle_y_slav</th>\n",
       "      <th>angle_z_slav</th>\n",
       "      <th>...</th>\n",
       "      <th>gz</th>\n",
       "      <th>angle_x</th>\n",
       "      <th>angle_y</th>\n",
       "      <th>angle_z</th>\n",
       "      <th>flex_0</th>\n",
       "      <th>flex_1</th>\n",
       "      <th>flex_2</th>\n",
       "      <th>flex_3</th>\n",
       "      <th>flex_4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1324857</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>-7.6025</td>\n",
       "      <td>-6.0893</td>\n",
       "      <td>-0.0395</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-51.5041</td>\n",
       "      <td>-0.5850</td>\n",
       "      <td>128.4897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>-6.3077</td>\n",
       "      <td>2.1024</td>\n",
       "      <td>173.3484</td>\n",
       "      <td>46.54</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1324923</td>\n",
       "      <td>-0.1556</td>\n",
       "      <td>-7.7252</td>\n",
       "      <td>-6.0055</td>\n",
       "      <td>-0.0168</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>-51.8179</td>\n",
       "      <td>-0.7485</td>\n",
       "      <td>128.1721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>-6.2625</td>\n",
       "      <td>2.2151</td>\n",
       "      <td>173.3543</td>\n",
       "      <td>53.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.48</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324989</td>\n",
       "      <td>-0.0706</td>\n",
       "      <td>-7.6629</td>\n",
       "      <td>-5.9863</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>-51.9095</td>\n",
       "      <td>-0.5827</td>\n",
       "      <td>128.0844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>-6.6953</td>\n",
       "      <td>2.2151</td>\n",
       "      <td>172.9446</td>\n",
       "      <td>53.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.48</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1325055</td>\n",
       "      <td>-0.1437</td>\n",
       "      <td>-7.6827</td>\n",
       "      <td>-6.0258</td>\n",
       "      <td>-0.0173</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>-0.0359</td>\n",
       "      <td>-51.8967</td>\n",
       "      <td>-0.7129</td>\n",
       "      <td>128.0941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-6.5472</td>\n",
       "      <td>2.4103</td>\n",
       "      <td>173.0195</td>\n",
       "      <td>53.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.48</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1325121</td>\n",
       "      <td>-0.0754</td>\n",
       "      <td>-7.6468</td>\n",
       "      <td>-6.0569</td>\n",
       "      <td>-0.0247</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>-51.7562</td>\n",
       "      <td>-0.5779</td>\n",
       "      <td>128.2378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>-6.4555</td>\n",
       "      <td>2.2943</td>\n",
       "      <td>173.1457</td>\n",
       "      <td>46.54</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.48</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>2115927</td>\n",
       "      <td>-0.2047</td>\n",
       "      <td>-7.8832</td>\n",
       "      <td>-5.8301</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>-53.4323</td>\n",
       "      <td>-1.1385</td>\n",
       "      <td>126.5441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-17.7203</td>\n",
       "      <td>7.1285</td>\n",
       "      <td>160.8104</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>2115993</td>\n",
       "      <td>-0.1975</td>\n",
       "      <td>-7.9125</td>\n",
       "      <td>-5.8163</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>-0.0303</td>\n",
       "      <td>-53.5491</td>\n",
       "      <td>-1.1454</td>\n",
       "      <td>126.4269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>-17.4835</td>\n",
       "      <td>7.0848</td>\n",
       "      <td>161.0488</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>2116059</td>\n",
       "      <td>-0.2131</td>\n",
       "      <td>-7.7671</td>\n",
       "      <td>-5.7355</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>-53.5434</td>\n",
       "      <td>-1.2044</td>\n",
       "      <td>126.4301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0277</td>\n",
       "      <td>-17.5427</td>\n",
       "      <td>7.6084</td>\n",
       "      <td>160.7789</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11980</th>\n",
       "      <td>2116125</td>\n",
       "      <td>-0.2131</td>\n",
       "      <td>-7.7671</td>\n",
       "      <td>-5.7355</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>-53.5404</td>\n",
       "      <td>-1.2343</td>\n",
       "      <td>126.4317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-17.5859</td>\n",
       "      <td>7.5819</td>\n",
       "      <td>160.7501</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>2116191</td>\n",
       "      <td>-0.2233</td>\n",
       "      <td>-7.8551</td>\n",
       "      <td>-5.7762</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>-53.5957</td>\n",
       "      <td>-1.2731</td>\n",
       "      <td>126.3746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>-17.4214</td>\n",
       "      <td>7.8207</td>\n",
       "      <td>160.7999</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11982 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp_ms  ax_slav  ay_slav  az_slav  gx_slav  gy_slav  gz_slav  \\\n",
       "0           1324857  -0.0772  -7.6025  -6.0893  -0.0395   0.0101   0.0029   \n",
       "1           1324923  -0.1556  -7.7252  -6.0055  -0.0168   0.0172   0.0329   \n",
       "2           1324989  -0.0706  -7.6629  -5.9863   0.0025   0.0275  -0.0064   \n",
       "3           1325055  -0.1437  -7.6827  -6.0258  -0.0173   0.0147  -0.0359   \n",
       "4           1325121  -0.0754  -7.6468  -6.0569  -0.0247   0.0211   0.0311   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "11977       2115927  -0.2047  -7.8832  -5.8301   0.0113   0.0145   0.0109   \n",
       "11978       2115993  -0.1975  -7.9125  -5.8163   0.0566   0.0164  -0.0303   \n",
       "11979       2116059  -0.2131  -7.7671  -5.7355   0.0605   0.0353  -0.0015   \n",
       "11980       2116125  -0.2131  -7.7671  -5.7355   0.0605   0.0353  -0.0015   \n",
       "11981       2116191  -0.2233  -7.8551  -5.7762   0.0319   0.0138  -0.0239   \n",
       "\n",
       "       angle_x_slav  angle_y_slav  angle_z_slav  ...      gz  angle_x  \\\n",
       "0          -51.5041       -0.5850      128.4897  ...  0.0177  -6.3077   \n",
       "1          -51.8179       -0.7485      128.1721  ...  0.0104  -6.2625   \n",
       "2          -51.9095       -0.5827      128.0844  ...  0.0202  -6.6953   \n",
       "3          -51.8967       -0.7129      128.0941  ...  0.0034  -6.5472   \n",
       "4          -51.7562       -0.5779      128.2378  ... -0.0090  -6.4555   \n",
       "...             ...           ...           ...  ...     ...      ...   \n",
       "11977      -53.4323       -1.1385      126.5441  ... -0.0070 -17.7203   \n",
       "11978      -53.5491       -1.1454      126.4269  ... -0.0022 -17.4835   \n",
       "11979      -53.5434       -1.2044      126.4301  ... -0.0277 -17.5427   \n",
       "11980      -53.5404       -1.2343      126.4317  ... -0.0124 -17.5859   \n",
       "11981      -53.5957       -1.2731      126.3746  ...  0.0369 -17.4214   \n",
       "\n",
       "       angle_y   angle_z  flex_0  flex_1  flex_2  flex_3  flex_4    Label  \n",
       "0       2.1024  173.3484   46.54    1.53     0.0     0.0   25.45  nothing  \n",
       "1       2.2151  173.3543   53.60    1.53     0.0     0.0   19.48  nothing  \n",
       "2       2.2151  172.9446   53.60    1.53     0.0     0.0   19.48  nothing  \n",
       "3       2.4103  173.0195   53.60    1.53     0.0     0.0   19.48  nothing  \n",
       "4       2.2943  173.1457   46.54    1.53     0.0     0.0   19.48  nothing  \n",
       "...        ...       ...     ...     ...     ...     ...     ...      ...  \n",
       "11977   7.1285  160.8104    0.00    0.00     0.0     0.0    7.56  nothing  \n",
       "11978   7.0848  161.0488    0.00    0.00     0.0     0.0    7.56  nothing  \n",
       "11979   7.6084  160.7789    0.00    0.00     0.0     0.0    7.56  nothing  \n",
       "11980   7.5819  160.7501    4.19    0.00     0.0     0.0    7.56  nothing  \n",
       "11981   7.8207  160.7999    4.19    0.00     0.0     0.0    7.56  nothing  \n",
       "\n",
       "[11982 rows x 30 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e397707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ee2a6e86e946d0be5e2e1bd7189f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.rand(1,29)\n",
    "datas = torch.rand(1,29)\n",
    "i=0\n",
    "while i<20:\n",
    "    \n",
    "    ### you need to put a streaming inout here\n",
    "    \n",
    "    \n",
    "    datas = torch.concat([datas,data])\n",
    "    i+=1\n",
    "datas = datas[1:,:]\n",
    "tas = convert_data_csv_train(datas.unsqueeze(0))\n",
    "tas = tas.movedim(1,2)\n",
    "answer = torch.argmax(model(tas))\n",
    "finalans = vocap[str(answer.item())]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
