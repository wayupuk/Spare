import random
import sys
from importlib.resources import files
import gradio as gr 
import tempfile
import torchaudio
import soundfile as sf
from cached_path import cached_path
import argparse
import os

from f5_tts.infer.utils_infer import (
    infer_process,
    load_model,
    load_vocoder,
    preprocess_ref_audio_text,
    remove_silence_for_generated_wav,
    save_spectrogram,
)
from f5_tts.model import DiT
from f5_tts.model.utils import seed_everything
import torch
from f5_tts.cleantext.number_tha import replace_numbers_with_thai
from f5_tts.cleantext.th_repeat import process_thai_repeat
from f5_tts.utils.whisper_api import translate_inference,transribe_inference
from f5_tts.infer.infer_gradio import *

#‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡πÉ‡∏´‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î Model ‡πÅ‡∏•‡∏∞ Vocab ‡πÄ‡∏ä‡πà‡∏ô default_model_base = "hf://VIZINTZOR/F5-TTS-THAI/model_350000.pt"
default_model_base = "hf://VIZINTZOR/F5-TTS-THAI/model_1000000.pt"
v2_model_base = "hf://VIZINTZOR/F5-TTS-TH-v2/model_250000.pt"
vocab_base = "./vocab/vocab.txt"
vocab_ipa_base = "./vocab/vocab_ipa.txt"

model_choices = ["Default", "V2", "Custom"]

global f5tts_model
f5tts_model = None

def load_f5tts(ckpt_path, vocab_path=vocab_base, model_type="v1"):
    if model_type == "v1":
        F5TTS_model_cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, text_mask_padding=False, conv_layers=4, pe_attn_head=1)
    elif model_type == "v2":
        F5TTS_model_cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, text_mask_padding=True, conv_layers=4, pe_attn_head=None)
        vocab_path = "./vocab/vocab_ipa.txt"
    model = load_model(DiT, F5TTS_model_cfg, ckpt_path, vocab_file = vocab_path, use_ema=True)
    print(f"Loaded model from {ckpt_path}")
    return model

vocoder = load_vocoder()

f5tts_model = load_f5tts(str(cached_path(default_model_base)))

def update_custom_model(selected_model):
    return gr.update(visible=selected_model == "Custom")
    
def update_v2_ipa(model):
    return gr.update(value="IPA" if model == "V2" else "Default")
    
def load_custom_model(model_choice,model_custom_path):
    torch.cuda.empty_cache()
    global f5tts_model
    model_path = default_model_base if model_choice == "Default" else v2_model_base
    if model_choice == "Custom":
        f5tts_model = load_f5tts(str(cached_path(model_custom_path)))
        return f"Loaded Custom Model {model_custom_path}"
    else:
        f5tts_model = load_f5tts(
            str(cached_path(model_path)),
            vocab_path = vocab_ipa_base if model_choice == "V2" else vocab_base,
            model_type = "v2" if model_choice == "V2" else "v1"
        )
        return f"Loaded Model {model_choice}"
    
def infer_tts(
    ref_audio_orig,
    ref_text,
    gen_text,
    remove_silence=True,
    cross_fade_duration=0.15,
    nfe_step=32,
    speed=1,
    cfg_strength=2,
    max_chars=250,
    seed=-1,
    lang_process="Default"
):
    global f5tts_model
    if f5tts_model is None:
        f5tts_model = load_f5tts(str(cached_path(default_model_base)))

    if seed == -1:
        seed = random.randint(0, sys.maxsize)
    seed_everything(seed)
    output_seed = seed

    if not ref_audio_orig:
        gr.Warning("Please provide reference audio.")
        return gr.update(), gr.update(), ref_text, output_seed

    if not gen_text.strip():
        gr.Warning("Please enter text to generate.")
        return gr.update(), gr.update(), ref_text, output_seed
    
    ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, ref_text)
    
    gen_text_cleaned = process_thai_repeat(replace_numbers_with_thai(gen_text)) 

    final_wave, final_sample_rate, combined_spectrogram = infer_process(
        ref_audio,
        ref_text,
        gen_text_cleaned,
        f5tts_model,
        vocoder,
        cross_fade_duration=float(cross_fade_duration),
        nfe_step=nfe_step,
        speed=speed,
        progress=gr.Progress(),
        cfg_strength=cfg_strength,
        set_max_chars=max_chars,
        use_ipa=True if lang_process == "IPA" else False
    )

    if remove_silence:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            sf.write(f.name, final_wave, final_sample_rate)
            remove_silence_for_generated_wav(f.name)
            final_wave, _ = torchaudio.load(f.name)
        final_wave = final_wave.squeeze().cpu().numpy()

    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp_spectrogram:
        spectrogram_path = tmp_spectrogram.name
        save_spectrogram(combined_spectrogram, spectrogram_path)
    
    print("seed:", output_seed)
    return (final_sample_rate, final_wave), spectrogram_path, ref_text, output_seed 

def transcribe_text(input_audio="",translate=False,model="large-v3-turbo",compute_type="float16",target_lg="th",source_lg='th'):
    if translate:
        output_text = translate_inference(text=transribe_inference(input_audio=input_audio,model=model,
                                          compute_type=compute_type,language=source_lg),target=target_lg)
    else:
        output_text = transribe_inference(input_audio=input_audio,model=model,
                                          compute_type=compute_type,language=source_lg)
    return output_text

def create_gradio_interface():
    with gr.Blocks(title="F5-TTS ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ üáπüá≠",theme=gr.themes.Ocean()) as demo:
        gr.Markdown("# F5-TTS ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢")
        gr.Markdown("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏î‡πâ‡∏ß‡∏¢ Zero-shot TTS ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢.")

        with gr.Row():
            model_select = gr.Radio(
                label="‡πÇ‡∏°‡πÄ‡∏î‡∏•",
                choices=model_choices,
                value="Default",
                interactive=True,
            )
            model_custom = gr.Textbox(label="‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á",value="hf://VIZINTZOR/F5-TTS-THAI/model_650000.pt", visible=False, interactive=True)
            model_status = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•", value="")
            load_custom_btn = gr.Button("‡πÇ‡∏´‡∏•‡∏î‚≠Æ",variant="primary")
    
        with gr.Tab(label="Text To Speech"):      
            with gr.Row():
                with gr.Column():
                    ref_text = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", lines=1, info="‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5-10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
                    ref_audio = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", type="filepath")
                    gen_text = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á", lines=4)
                    generate_btn = gr.Button("üöÄ‡∏™‡∏£‡πâ‡∏≤‡∏á",variant="primary")

                    with gr.Accordion(label="‚öôÔ∏è‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"):
                        lang_input = gr.Radio(label="‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤",choices=["Default","IPA"],value="Default",info="IPA ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• V2 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
                        remove_silence = gr.Checkbox(label="Remove Silence", value=True)
                        speed = gr.Slider(label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß", value=1, minimum=0.3, maximum=1.5, step=0.1)
                        cross_fade_duration = gr.Slider(label="Cross Fade Duration", value=0.15, minimum=0, maximum=1, step=0.05)
                        nfe_step = gr.Slider(label="NFE Step", value=32, minimum=7, maximum=64, step=1, info="‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏•‡∏á")
                        cfg_strength = gr.Slider(label="CFG Strength", value=2, minimum=1, maximum=4, step=0.1)
                        max_chars = gr.Number(label="‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô", minimum=50, maximum=1000, value=300,
                                            info="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÜ")
                        seed = gr.Number(label="Seed", value=-1, precision=0, info="-1 = ‡∏™‡∏∏‡πà‡∏° Seed")
                        
                with gr.Column():
                    output_audio = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á", type="filepath")
                    seed_output = gr.Textbox(label="Seed", interactive=False)
                    
            gr.Examples(
                examples=[
                    [
                        "./src/f5_tts/infer/examples/thai_examples/ref_gen_1.wav",
                        "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô.",
                        "‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"
                    ],
                    [
                        "./src/f5_tts/infer/examples/thai_examples/ref_gen_2.wav",
                        "‡∏â‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏°‡∏ú‡∏±‡∏™‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡πá‡∏ô‡∏™‡∏ö‡∏≤‡∏¢.",
                        "‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢"
                    ],
                    [
                        "./src/f5_tts/infer/examples/thai_examples/ref_gen_3.wav",
                        "‡∏Å‡∏π‡πâ‡∏î‡∏≠‡∏≤‡∏ü‡πÄ‡∏ï‡πâ‡∏≠‡∏ô‡∏π‡∏ô‡πÑ‡∏ô‡∏ó‡πå‡∏ó‡∏π‡∏°‡∏µ‡∏ó‡∏¢‡∏π.",
                        "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏•‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞"
                    ],
                    [
                        "./src/f5_tts/infer/examples/thai_examples/ref_gen_4.wav",
                        "‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏à‡∏∞‡∏ï‡∏∑‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞.",
                        "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏â‡∏±‡∏ô‡πÑ‡∏õ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏•‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏≤‡∏¢‡∏´‡∏≤‡∏î ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡∏ã‡∏±‡∏î‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏ó‡∏µ‡πà‡∏ä‡∏ß‡∏ô‡πÉ‡∏´‡πâ‡πÉ‡∏à‡∏™‡∏á‡∏ö."
                    ]
                ],
                inputs=[ref_audio, ref_text, gen_text],
                fn=infer_tts,
                cache_examples=False,
                label="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
            )
            
            gr.Markdown("# ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
            gr.Markdown(
                        """ - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ "‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠ max_chars ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏•‡∏á ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î NFE Step ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÑ‡∏î‡πâ
                        ‡∏õ‡∏£‡∏±‡∏ö NFE Step ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 7 ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏û‡∏≠‡∏ü‡∏±‡∏á‡πÑ‡∏î‡πâ.
                        - ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ.
                        - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ref_text ‡∏´‡∏£‡∏∑‡∏≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Good Morning > ‡∏Å‡∏π‡πâ‡∏î‡∏°‡∏≠‡∏£‡πå‡∏ô‡∏¥‡πà‡∏á.
                        - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô.
                        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏´‡πâ‡∏ä‡πâ‡∏≤‡∏•‡∏á ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å ‡πÄ‡∏ä‡πà‡∏ô 2-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                        - ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÜ ‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß 1-3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 0.8-0.9.
                        - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á.
                    """
            )

            load_custom_btn.click(
                fn=load_custom_model,
                inputs=[
                    model_select,
                    model_custom
                    ],
                outputs=model_status
            )
            
            model_select.change(
                fn=update_custom_model,
                inputs=model_select,
                outputs=model_custom
            )
            
            model_select.change(
                fn=update_v2_ipa,
                inputs=model_select,
                outputs=lang_input
            )
            
            generate_btn.click(
                fn=infer_tts,
                inputs=[
                    ref_audio,
                    ref_text,
                    gen_text,
                    remove_silence,
                    cross_fade_duration,
                    nfe_step,
                    speed,
                    cfg_strength,
                    max_chars,
                    seed,
                    lang_input
                ],
                outputs=[
                    output_audio,
                    gr.Image(label="Spectrogram",visible=False),
                    ref_text,
                    seed_output
                ]
            )
            
        with gr.Tab(label="Multi Speech"):
            with gr.Row():
                gr.Markdown(
                    """
                    **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**                                                                      
                    {‡∏õ‡∏Å‡∏ï‡∏¥} ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö    
                    {‡πÄ‡∏®‡∏£‡πâ‡∏≤} ‡∏ú‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ô‡∏∞‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ...      
                    {‡πÇ‡∏Å‡∏£‡∏ò} ‡∏£‡∏π‡πâ‡πÑ‡∏´‡∏°! ‡πÄ‡∏ò‡∏≠‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà!       
                    {‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö} ‡∏â‡∏±‡∏ô‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì ‡πÅ‡∏ï‡πà‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö‡∏ô‡∏∞.   
                    """
                )
            gr.Markdown(
                """‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏û‡∏π‡∏î ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏û‡∏π‡∏î"."""
            )

            # Regular speech type (mandatory)
            with gr.Row() as regular_row:
                with gr.Column():
                    regular_name = gr.Textbox(value="‡∏õ‡∏Å‡∏ï‡∏¥", label="‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå/‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î")
                    regular_insert = gr.Button("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏≥‡∏Å‡∏±‡∏ö", variant="secondary")
                regular_audio = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö", type="filepath")
                regular_ref_text = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", lines=2)

            # Regular speech type (max 100)
            max_speech_types = 100
            speech_type_rows = [regular_row]
            speech_type_names = [regular_name]
            speech_type_audios = [regular_audio]
            speech_type_ref_texts = [regular_ref_text]
            speech_type_delete_btns = [None]
            speech_type_insert_btns = [regular_insert]

            # Additional speech types (99 more)
            for i in range(max_speech_types - 1):
                with gr.Row(visible=False) as row:
                    with gr.Column():
                        name_input = gr.Textbox(label="‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå/‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î")
                        delete_btn = gr.Button("‡∏•‡∏ö", variant="secondary")
                        insert_btn = gr.Button("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏≥‡∏Å‡∏±‡∏ö", variant="secondary")
                    audio_input = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", type="filepath")
                    ref_text_input = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", lines=2)
                speech_type_rows.append(row)
                speech_type_names.append(name_input)
                speech_type_audios.append(audio_input)
                speech_type_ref_texts.append(ref_text_input)
                speech_type_delete_btns.append(delete_btn)
                speech_type_insert_btns.append(insert_btn)

            # Button to add speech type
            add_speech_type_btn = gr.Button("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏û‡∏π‡∏î",variant="secondary")

            # Keep track of autoincrement of speech types, no roll back
            speech_type_count = 1

            # Function to add a speech type
            def add_speech_type_fn():
                row_updates = [gr.update() for _ in range(max_speech_types)]
                global speech_type_count
                if speech_type_count < max_speech_types:
                    row_updates[speech_type_count] = gr.update(visible=True)
                    speech_type_count += 1
                else:
                    gr.Warning("Exhausted maximum number of speech types. Consider restart the app.")
                return row_updates

            add_speech_type_btn.click(add_speech_type_fn, outputs=speech_type_rows)

            # Function to delete a speech type
            def delete_speech_type_fn():
                return gr.update(visible=False), None, None, None

            # Update delete button clicks
            for i in range(1, len(speech_type_delete_btns)):
                speech_type_delete_btns[i].click(
                    delete_speech_type_fn,
                    outputs=[speech_type_rows[i], speech_type_names[i], speech_type_audios[i], speech_type_ref_texts[i]],
                )

            # Text input for the prompt
            gen_text_input_multistyle = gr.Textbox(
                label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
                lines=10,
                placeholder="""‡∏õ‡πâ‡∏≠‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î (‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå) ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏•‡πá‡∏≠‡∏Å ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô:
                {‡∏õ‡∏Å‡∏ï‡∏¥} ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö
                {‡πÄ‡∏®‡∏£‡πâ‡∏≤} ‡∏ú‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ô‡∏∞‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ...
                {‡πÇ‡∏Å‡∏£‡∏ò} ‡∏£‡∏π‡πâ‡πÑ‡∏´‡∏°! ‡πÄ‡∏ò‡∏≠‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà!
                {‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö} ‡∏â‡∏±‡∏ô‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì ‡πÅ‡∏ï‡πà‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö‡∏ô‡∏∞.""",
            )

            def make_insert_speech_type_fn(index):
                def insert_speech_type_fn(current_text, speech_type_name):
                    current_text = current_text or ""
                    speech_type_name = speech_type_name or "None"
                    updated_text = current_text + f"{{{speech_type_name}}} "
                    return updated_text

                return insert_speech_type_fn

            for i, insert_btn in enumerate(speech_type_insert_btns):
                insert_fn = make_insert_speech_type_fn(i)
                insert_btn.click(
                    insert_fn,
                    inputs=[gen_text_input_multistyle, speech_type_names[i]],
                    outputs=gen_text_input_multistyle,
                )

            with gr.Accordion("‚öôÔ∏è‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤", open=False):
                remove_silence_multistyle = gr.Checkbox(
                    label="Remove Silences",
                    value=True,
                )
                ms_use_ipa = gr.Checkbox(label="‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤(IPA)", value=False, info="‡πÉ‡∏ä‡πâ IPA ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• V2 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
                ms_cross_fade_duration = gr.Slider(label="Cross Fade Duration", value=0.15, minimum=0, maximum=1, step=0.05)
                ms_nfe_step = gr.Slider(label="NFE Step", value=32, minimum=7, maximum=64, step=1, info="‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏•‡∏á")


            # Generate button
            generate_multistyle_btn = gr.Button("üöÄ‡∏™‡∏£‡πâ‡∏≤‡∏á", variant="primary")

            # Output audio
            audio_output_multistyle = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á")

            def generate_multistyle_speech(
                gen_text,
                cross_fade_duration,
                nfe_step,
                lang_process,
                *args,
            ):
                speech_type_names_list = args[:max_speech_types]
                speech_type_audios_list = args[max_speech_types : 2 * max_speech_types]
                speech_type_ref_texts_list = args[2 * max_speech_types : 3 * max_speech_types]
                remove_silence = args[3 * max_speech_types]
                # Collect the speech types and their audios into a dict
                speech_types = OrderedDict()

                ref_text_idx = 0
                for name_input, audio_input, ref_text_input in zip(
                    speech_type_names_list, speech_type_audios_list, speech_type_ref_texts_list
                ):
                    if name_input and audio_input:
                        speech_types[name_input] = {"audio": audio_input, "ref_text": ref_text_input}
                    else:
                        speech_types[f"@{ref_text_idx}@"] = {"audio": "", "ref_text": ""}
                    ref_text_idx += 1

                # Parse the gen_text into segments
                segments = parse_speechtypes_text(gen_text)

                # For each segment, generate speech
                generated_audio_segments = []
                current_style = "Regular"

                for segment in segments:
                    style = segment["style"]
                    text = segment["text"]

                    if style in speech_types:
                        current_style = style
                    else:
                        gr.Warning(f"Type {style} is not available, will use Regular as default.")
                        current_style = "Regular"

                    try:
                        ref_audio = speech_types[current_style]["audio"]
                    except KeyError:
                        gr.Warning(f"Please provide reference audio for type {current_style}.")
                        return [None] + [speech_types[style]["ref_text"] for style in speech_types]
                    ref_text = speech_types[current_style].get("ref_text", "")

                    ms_cleaned_text = process_thai_repeat(replace_numbers_with_thai(text))
                    # Generate speech for this segment
                    audio_out, _, ref_text_out = infer(
                        ref_audio, 
                        ref_text, 
                        ms_cleaned_text, 
                        f5tts_model, 
                        vocoder, 
                        remove_silence, 
                        cross_fade_duration=cross_fade_duration, 
                        nfe_step=nfe_step, 
                        show_info=print,
                        use_ipa=lang_process,
                    )  # show_info=print no pull to top when generating
                    sr, audio_data = audio_out

                    generated_audio_segments.append(audio_data)
                    speech_types[current_style]["ref_text"] = ref_text_out

                # Concatenate all audio segments
                if generated_audio_segments:
                    final_audio_data = np.concatenate(generated_audio_segments)
                    return [(sr, final_audio_data)] + [speech_types[style]["ref_text"] for style in speech_types]
                else:
                    gr.Warning("No audio generated.")
                    return [None] + [speech_types[style]["ref_text"] for style in speech_types]

            generate_multistyle_btn.click(
                generate_multistyle_speech,
                inputs=[
                    gen_text_input_multistyle,
                    ms_cross_fade_duration,
                    ms_nfe_step,
                    ms_use_ipa    
                ]
                + speech_type_names
                + speech_type_audios
                + speech_type_ref_texts
                + [
                    remove_silence_multistyle,
                ],
                outputs=[audio_output_multistyle] + speech_type_ref_texts,
            )

            # Validation function to disable Generate button if speech types are missing
            def validate_speech_types(gen_text, regular_name, *args):
                speech_type_names_list = args

                # Collect the speech types names
                speech_types_available = set()
                if regular_name:
                    speech_types_available.add(regular_name)
                for name_input in speech_type_names_list:
                    if name_input:
                        speech_types_available.add(name_input)

                # Parse the gen_text to get the speech types used
                segments = parse_speechtypes_text(gen_text)
                speech_types_in_text = set(segment["style"] for segment in segments)

                # Check if all speech types in text are available
                missing_speech_types = speech_types_in_text - speech_types_available

                if missing_speech_types:
                    # Disable the generate button
                    return gr.update(interactive=False)
                else:
                    # Enable the generate button
                    return gr.update(interactive=True)

            gen_text_input_multistyle.change(
                validate_speech_types,
                inputs=[gen_text_input_multistyle, regular_name] + speech_type_names,
                outputs=generate_multistyle_btn,
            )

        with gr.Tab(label="Speech to Text"):
            gr.Markdown("‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏• [Whisper](https://github.com/openai/whisper) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ [faster-whisper](https://github.com/SYSTRAN/faster-whisper)")
            with gr.Row():
                with gr.Column():
                    ref_audio_input = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö",type="filepath")
                    is_translate = gr.Checkbox(label="‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤")
                    generate_btn_stt = gr.Button("‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",variant="primary")

                    with gr.Accordion(label="‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤",open=False):
                        model_wp = gr.Dropdown(label="Model",choices=['base','small','medium','large-v2','large-v3','large-v3-turbo'],value="large-v2")
                        compute_type = gr.Dropdown(label="Compute Type",choices=["float32","float16","int8_float16","int8"],value="float16")
                        source_lg = gr.Dropdown(label="‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö",choices=["Auto",'th',"en"],value="Auto")
                        target_lg = gr.Dropdown(label="‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•",choices=['th',"en"],value="th")

                with gr.Column():
                    output_ref_text = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö",lines=3,show_copy_button=True)
            
            generate_btn_stt.click(fn=transcribe_text,
                                   inputs=[ref_audio_input,is_translate,
                                           model_wp,compute_type,target_lg,source_lg],
                                   outputs=output_ref_text)
            
        return demo

def main():
    parser = argparse.ArgumentParser(description="Share Link")
    parser.add_argument("--share", action="store_true")
    args = parser.parse_args()

    demo = create_gradio_interface()
    demo.launch(inbrowser=True, share=args.share)

if __name__ == "__main__":
    main()



